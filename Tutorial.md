# Tourism Trends (Italy)

Pipeline Ù‡Ø¯Ù: **Kafka â†’ Spark (batch/stream) â†’ Parquet/Postgres â†’ Grafana/Power BI**
 Ø¯Ø§Ø¯Ù‡Ù” ÙÛŒÚ© Ø§Ù…Ø§ **Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± ÙˆØ§Ù‚Ø¹ÛŒØª** (Ø´Ù‡Ø±/ÙØ±ÙˆØ¯Ú¯Ø§Ù‡/Ù‡ØªÙ„ ÙˆØ§Ù‚Ø¹ÛŒØ› ÙˆØ²Ù†â€ŒØ¯Ù‡ÛŒ Ø¨Ø§ Ø¬Ù…Ø¹ÛŒØª/ÙØµÙ„/Ø¢Ø¨â€ŒÙˆÙ‡ÙˆØ§).

## 1.Python venv & Ù¾Ø§ÛŒÙ‡â€ŒÙ‡Ø§ (Ø¨Ø¯ÙˆÙ† Docker)

```
python3 -m venv ~/myenvironments/Tourism
source ~/myenvironments/Tourism/bin/activate
pip install --upgrade pip

# Python libs (ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡ + ETL + Ø°Ø®ÛŒØ±Ù‡ + Ù…ØµÙˆØ±Ø³Ø§Ø²ÛŒ)
pip install faker pyyaml pandas numpy kafka-python pyarrow psycopg2-binary matplotlib jupyter rapidfuzz

# (Ø§Ø®ØªÛŒØ§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ parquet Ø³Ø±ÛŒØ¹â€ŒØªØ±)
pip install fastparquet

# Postgres (Ù…Ø­Ù„ÛŒ)
sudo apt update
sudo apt install -y postgresql postgresql-contrib

```

Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ CLI Ù…ÙÛŒØ¯:

```
sudo apt install -y csvkit        # Ú©Ø§Ø± Ø¨Ø§ CSV Ø§Ø² Ø®Ø· ÙØ±Ù…Ø§Ù†
sudo apt install -y gdal-bin      # Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ (ogr2ogr Ùˆ ...)
sudo apt install -y osmium-tool   # Ø§Ø³ØªØ®Ø±Ø§Ø¬ OSM/Ù‡ØªÙ„â€ŒÙ‡Ø§ Ø§Ø² PBF

```

## 2) Grafana (Ø³ÛŒØ³ØªÙ…â€ŒØ¹Ø§Ù…Ù„ Debian/Ubuntu)

```
wget https://dl.grafana.com/oss/release/grafana_10.4.2_amd64.deb
sudo apt install -y musl           # dependency
sudo dpkg -i grafana_10.4.2_amd64.deb
rm grafana_10.4.2_amd64.deb

sudo systemctl enable grafana-server
sudo systemctl start grafana-server
# login: http://127.0.0.1:3000 (default: admin / admin)

```

## 3) Ø³Ø§Ø®ØªØ§Ø± Ù¾Ø±ÙˆÚ˜Ù‡

```
Projects/Tourism/
â”œâ”€ scripts/
â”‚  â”œâ”€ clean_airports_it.py
â”‚  â”œâ”€ clean_cities_geonames.py
â”‚  â”œâ”€ extract_households_population.py
â”‚  â”œâ”€ istat_utils.py
â”‚  â”œâ”€ clean_istat_abitazioni.py
â”‚  â”œâ”€ clean_istat_famiglie.py
â”‚  â”œâ”€ peek_istr_lav.py
â”‚  â”œâ”€ clean_istat_commuting.py
â”‚  â”œâ”€ merge_cities_with_households.py
â”‚  â”œâ”€ name_utils.py
â”‚  â””â”€ merge_cities_all.py
â”œâ”€ Dataset/                 # ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… (OurAirports, GeoNames, ISTAT, OSM PBF)
â””â”€ data/
   â””â”€ curated/             # Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ÛŒ ØªÙ…ÛŒØ² Ùˆ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§
      â””â”€ reports/

```

## 4) Ø¯ÛŒØªØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¬Ø¹ Ùˆ Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ

### 4.1 OurAirports â†’ `airports_it.csv`

- **Ù‡Ø¯Ù:** ÙÙ‚Ø· ÙØ±ÙˆØ¯Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ÛŒØªØ§Ù„ÛŒØ§ Ø¨Ø§ IATA Ø³Ù‡â€ŒØ­Ø±ÙÛŒ Ùˆ Ù…Ø®ØªØµØ§Øª Ù…Ø¹ØªØ¨Ø±.
- ÙˆØ±ÙˆØ¯ÛŒ: `Dataset/airports.csv` (Ø®Ø§Ù… OurAirports)
- Ø®Ø±ÙˆØ¬ÛŒ: `data/curated/airports_it.csv`



```
mkdir -p data/curated
python scripts/clean_airports_it.py /path/to/airports.csv
# Ú†Ú©:
python - <<'PY'
import pandas as pd
df = pd.read_csv("data/curated/airports_it.csv")
print(df.shape, df.head().to_string(index=False))
PY

```

**Ø³ØªÙˆÙ†â€ŒÙ‡Ø§:** `airport_code, icao_code, name, type, lat, lon, city_name, region_code, ident`
 **Dedup:** Ø§Ú¯Ø± IATA ØªÚ©Ø±Ø§Ø±ÛŒ Ø¨ÙˆØ¯ â†’ `large_airport` > `medium` > `small`.



### 4.2 GeoNames (IT.txt) â†’ `cities_it.csv`

- **Ù‡Ø¯Ù:** Ù‡Ù…Ù‡Ù” Ø´Ù‡Ø±Ù‡Ø§/Ø¢Ø¨Ø§Ø¯ÛŒâ€ŒÙ‡Ø§ (feature_class='P') Ø¨Ø§ Ù…Ø®ØªØµØ§Øª Ùˆ Ø¬Ù…Ø¹ÛŒØª.
- ÙˆØ±ÙˆØ¯ÛŒ: `data/raw/geonames/IT.txt` (Ø§Ø² GeoNames)
- Ø®Ø±ÙˆØ¬ÛŒ: `data/curated/cities_it.csv`

```
python scripts/clean_cities_geonames.py /path/to/IT.txt
```

**Ø³ØªÙˆÙ†â€ŒÙ‡Ø§:** `city_id, city_name, admin1_code, region, lat, lon, population`



### 4.3 ISTAT â€” Households & Population (Ù¾Ø§ÛŒÙ‡)

- **Households:** Ø§Ø² `DCSS_FAM_POP` (Ø´Ø§Ø®Øµ `NPHH_AV`)
- **Population (Ø§Ø®ØªÛŒØ§Ø±ÛŒ):** Ø§Ø² `DCSS_POP_DEMCITMIG` (Ø´Ø§Ø®Øµ `RESPOP_AV` ÛŒØ§ `RESPOP_MIN_AV`)
- Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§:
  - `data/curated/istat_households.csv` â†’ `territory_code, territory_name, year, households`
  - `data/curated/istat_population.csv` â†’ `territory_code, territory_name, year, population` (Ø§Ú¯Ø± Ø³ÛŒØ³ØªÙ… Ø§Ø¬Ø§Ø²Ù‡ Ø¯Ø§Ø¯)

```
python scripts/extract_households_population.py
```

> *Ù†Ú©ØªÙ‡:* ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ISTAT Ø­Ø¬ÛŒÙ… Ùˆ Ú¯Ø§Ù‡ÛŒ Ø¨Ø§ `|`/`;` Ù‡Ø³ØªÙ†Ø¯. `istat_utils.py` Ø®ÙˆØ§Ù†Ø¯Ù† Ù…Ù‚Ø§ÙˆÙ… Ø¨Ø§ ØªØ´Ø®ÛŒØµ Ø¬Ø¯Ø§Ú©Ù†Ù†Ø¯Ù‡/Ú©ÙˆØªÛŒØ´Ù† Ø±Ø§ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.



### 4.4 ISTAT â€” Abitazioni (Homes) â†’ `istat_homes.csv`

- ÙˆØ±ÙˆØ¯ÛŒ: `DCSS_ABITAZIONI`
- Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§: `NUM_DW_AV` (Ú©Ù„ ÙˆØ§Ø­Ø¯ Ù…Ø³Ú©ÙˆÙ†ÛŒ)ØŒ `NUM_OCC_DW_AV` (Ø§Ø´ØºØ§Ù„â€ŒØ´Ø¯Ù‡)
- Ø®Ø±ÙˆØ¬ÛŒ: `territory_name, dwellings_total, dwellings_occupied, occupied_share`

```
python scripts/clean_istat_abitazioni.py
```



### 4.5 ISTAT â€” Famiglie (Families by size) â†’ `istat_families.csv`

- ÙˆØ±ÙˆØ¯ÛŒ: `DCSS_FAMIGLIE`
- Ø®Ø±ÙˆØ¬ÛŒ: `families_total, families_3plus_share, avg_family_size_from_istat`

```
python scripts/clean_istat_famiglie.py
```



### 4.6 ISTAT â€” Istruzione/Lavoro/Commuting â†’ `istat_commuting.csv`

- ÙˆØ±ÙˆØ¯ÛŒ: `DCSS_ISTR_LAV_PEN_2`
- Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ Ø´Ù…Ø§: `RESPOP_AV`, `RP_COM_DAY`
- Ø®Ø±ÙˆØ¬ÛŒ: `resident_population, commuting_population, commuting_ratio`

```
python scripts/peek_istr_lav.py      # ØªØ´Ø®ÛŒØµ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§/Ú©Ø¯ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ (Ø³Ø¨ÙÚ©)
python scripts/clean_istat_commuting.py
```



## 5) Ø§Ø¯ØºØ§Ù… Ù…Ø±Ø¬Ø¹â€ŒÙ‡Ø§ÛŒ Ø´Ù‡Ø±ÛŒ

### 5.1 Merge Ø³Ø§Ø¯Ù‡ (households ÙÙ‚Ø·) â†’ `cities_it_enriched.csv`

```
python scripts/merge_cities_with_households.py
```

**Ø³ØªÙˆÙ†â€ŒÙ‡Ø§:** `city_id, city_name, region, lat, lon, population, households, avg_family_size`

- `avg_family_size` = `population / households` (fallback)

### 5.2 Merge Ú©Ø§Ù…Ù„ â†’ `cities_it_enriched_full.csv`

Ø§Ø¯ØºØ§Ù… `cities_it.csv` Ø¨Ø§ Ù‡Ù…Ù‡Ù” Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ÛŒ ISTAT (households, homes, families, commuting).

```
python scripts/merge_cities_all.py
```

Ø®Ø±ÙˆØ¬ÛŒ: `data/curated/cities_it_enriched_full.csv`
 Ú¯Ø²Ø§Ø±Ø´ unmatched: `data/curated/reports/unmatched_top500.csv`



## 6) Ù†Ú©Ø§Øª Ú©ÛŒÙÛŒØª Ùˆ Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ

- **ISTAT CSVâ€ŒÙ‡Ø§ Ø®Ø±Ø§Ø¨/Quote Ù†Ø§Ù‡Ù…Ú¯ÙˆÙ†:** Ø¯Ø± utilÙ‡Ø§ Ø§Ø² `quoting=QUOTE_NONE`, `on_bad_lines='skip'`, Ùˆ ØªØ´Ø®ÛŒØµ Ø®ÙˆØ¯Ú©Ø§Ø± `sep` Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡.
- **Ù†Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§:** Ø¨Ø§ `find_col` Ø¨Ù‡ ØµÙˆØ±Øª **case-insensitive** Ùˆ Ø¶Ø¯ ÙØ§ØµÙ„Ù‡/Quote Ù¾ÛŒØ¯Ø§ Ù…ÛŒâ€ŒØ´Ù†.
- **Ø³Ø§Ù„:** Ø§Ú¯Ø± Ø³ØªÙˆÙ† `TIME` Ù‚Ø§Ù„Ø¨ ØºÛŒØ±Ø¹Ø¯Ø¯ÛŒ Ø¯Ø§Ø´Øª (Ù…Ø«Ù„ Â«Censimento 2021Â»)ØŒ Ø³Ø§Ù„ Ø¨Ø§ regex Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒØ´Ù‡.
- **Chunking:** Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ú†Ù†Ø¯Ú¯ÛŒÚ¯ÛŒØŒ Ù‡Ù…Ù‡Ù” readerÙ‡Ø§ chunkÛŒ Ù‡Ø³ØªÙ† (`chunksize=100kâ€“150k`).



## 7) Ø¢Ù†Ú†Ù‡ Ø¢Ù…Ø§Ø¯Ù‡Ù” Ù…ØµØ±Ù ProducerÙ‡Ø§Ø³Øª

- `data/curated/airports_it.csv` â†’ Ù…Ø±Ø¬Ø¹ ÙØ±ÙˆØ¯Ú¯Ø§Ù‡â€ŒÙ‡Ø§ (IATA + lat/lon)
- `data/curated/cities_it.csv` â†’ Ù‡Ù…Ù‡Ù” Ø´Ù‡Ø±Ù‡Ø§/Ø¢Ø¨Ø§Ø¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø§ Ø¬Ù…Ø¹ÛŒØª/Ù…Ø®ØªØµØ§Øª
- `data/curated/cities_it_enriched_full.csv` â†’ Ù…Ø±Ø¬Ø¹ Ø´Ù‡Ø±ÛŒ ØºÙ†ÛŒâ€ŒØ´Ø¯Ù‡ Ø¨Ø§:
  - `households, avg_family_size`
  - `dwellings_total, occupied_share`
  - `families_total, families_3plus_share, avg_family_size_from_istat`
  - `resident_population_istat, commuting_population, commuting_ratio`

> Ø§ÛŒÙ† ÙØ§ÛŒÙ„ Ø¨Ø±Ø§ÛŒ ÙˆØ²Ù†â€ŒØ¯Ù‡ÛŒ ØªÙ‚Ø§Ø¶Ø§ØŒ seasonality city-levelØŒ Ùˆ Ù†Ù‚Ø´Ù‡Ù” Grafana (Geo map) Ú©Ø§Ù…Ù„Ø§Ù‹ Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³Øª.



## 8) Ù‚Ø¯Ù…â€ŒÙ‡Ø§ÛŒ Ø¨Ø¹Ø¯ÛŒ (Outline)

- `configs/cities.yaml` Ùˆ `configs/dist_params.yaml` Ø±Ø§ Ø§Ø² `cities_it_enriched_full.csv` Ø¨Ø³Ø§Ø²ÛŒÙ… (peak_months, weekday_weight, coastal_flagâ€¦).
- OSM â†’ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‡ØªÙ„â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ (name + lat/lon + stars Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯) â†’ `configs/hotels.yaml`.
- Ø³Ù‡ Producer:
  - `producers/bookings_producer.py`
  - `producers/flights_producer.py`
  - `producers/weather_producer.py`
- Spark:
  - `spark/streaming_city_kpis.py` (Structured Streaming â†’ gold city_day_kpis)
  - `spark/batch_monthly_rollup.py`
- Grafana:
  - Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ realtime (consumer lag, msgs/sec, arrivals_today, cancel_rate, ADR proxy, map)



Ø­Ø§Ù„Ø§ Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒÙ… Ù‡Ù…Ù‡Ù” Ø¯ÛŒØªØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ ØªÙ…ÛŒØ²Ø´Ø¯Ù‡ Ø±Ùˆ ÛŒÚ©â€ŒØ¬Ø§ â€œÙ…Ø±Ø¬Ø¹ Ø´Ù‡Ø±Ù‡Ø§â€ Ú©Ù†ÛŒÙ… ØªØ§ ProducerÙ‡Ø§ Ù…Ø³ØªÙ‚ÛŒÙ… Ø§Ø²Ø´ Ø¨Ø®ÙˆÙ†Ù†.

## Ù‡Ø¯Ù Ø§ÛŒÙ† Ù…Ø±Ø­Ù„Ù‡

Ø³Ø§Ø®Øª ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ:

```
data/curated/cities_it_enriched_full.csv
```

Ø¨Ø§ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ:

- `city_id, city_name, region, lat, lon, population` (Ø§Ø² GeoNames)
- `households, avg_family_size`
- `dwellings_total, dwellings_occupied, occupied_share`
- `families_total, families_3plus_share, avg_family_size_from_istat`
- `resident_population_istat, commuting_population, commuting_ratio`

> Ú†ÙˆÙ† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ISTAT Ú©Ø¯ Â«Ú©ÙÙ…ÙˆÙ†Ù‡Â» (`territory_code` Ù…Ø«Ù„ 001001) Ø¯Ø§Ø±Ù†Ø¯ ÙˆÙ„ÛŒ `cities_it.csv` Ø§Ø² GeoNames ÙØ§Ù‚Ø¯ Ø§ÛŒÙ† Ú©Ø¯Ù‡ØŒ merge Ø±Ø§ **Ù†Ø§Ù…â€ŒÙ…Ø­ÙˆØ±** (normalize name) Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ¯ÛŒÙ… Ùˆ Ú¯Ø²Ø§Ø±Ø´ unmatched Ù‡Ù… ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ….



## 1) Ø§Ø¨Ø²Ø§Ø± Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù†Ø§Ù…â€ŒÙ‡Ø§ (Ø§Ú¯Ø± Ù‚Ø¨Ù„Ø§Ù‹ Ù†Ø¯Ø§Ø±ÛŒ)

```
scripts/name_utils.py
#!/usr/bin/env python3
import re, unicodedata
import pandas as pd

def norm_text(s: str) -> str:
    if pd.isna(s): return ""
    s = s.strip().lower()
    s = "".join(c for c in unicodedata.normalize("NFKD", s) if not unicodedata.combining(c))
    s = re.sub(r"[â€™'`]", "", s)        # Ø­Ø°Ù Ø§Ù¾ÙˆØ³ØªØ±ÙˆÙ
    s = re.sub(r"[^a-z0-9]+", " ", s) # ÙÙ‚Ø· Ø­Ø±ÙˆÙ/Ø§Ø¹Ø¯Ø§Ø¯
    return s.strip()

def clean_istat_name(s: str) -> str:
    s = norm_text(s)
    # Ø­Ø°Ù Ù¾ÛŒØ´ÙˆÙ†Ø¯Ù‡Ø§ÛŒ Ø§Ø¯Ø§Ø±ÛŒ Ø±Ø§ÛŒØ¬
    patterns = [
        r"^comune di ", r"^citta metropolitana di ", r"^provincia di ",
        r"^unione dei comuni .*? ", r"^territorio di ", r"^municipio di ",
        r"^regione .*? ", r"^zona .*? ", r"^ambito .*? "
    ]
    for p in patterns:
        s = re.sub(p, "", s)
    return s.strip()
```

------

## 2) Ù…Ø±Ø¬ Ù†Ù‡Ø§ÛŒÛŒ Ù‡Ù…Ù‡Ù” Ø¯ÛŒØªØ§Ø³Øªâ€ŒÙ‡Ø§

```
scripts/merge_cities_all.py
#!/usr/bin/env python3
import os, pandas as pd
from name_utils import norm_text, clean_istat_name

BASE = "/home/tahmast/Projects/Tourism"
CUR = os.path.join(BASE, "data/curated")

# ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§
CITIES = os.path.join(CUR, "cities_it.csv")                   # GeoNames: city_id, city_name, region, lat, lon, population
HH     = os.path.join(CUR, "istat_households.csv")            # territory_name, households
HOMES  = os.path.join(CUR, "istat_homes.csv")                 # territory_name, dwellings_total, dwellings_occupied, occupied_share
FAMS   = os.path.join(CUR, "istat_families.csv")              # territory_name, families_total, families_3plus_share, avg_family_size_from_istat
COMM   = os.path.join(CUR, "istat_commuting.csv")             # territory_name, resident_population, commuting_population, commuting_ratio

OUT    = os.path.join(CUR, "cities_it_enriched_full.csv")
REPORT = os.path.join(CUR, "reports")
os.makedirs(REPORT, exist_ok=True)

def load_or_empty(path):
    if not os.path.exists(path):
        return pd.DataFrame()
    return pd.read_csv(path, dtype=str)

def norm_df(df, name_col):
    if name_col in df.columns:
        df[name_col+"_norm"] = df[name_col].map(clean_istat_name)
    return df

def main():
    # 1) GeoNames cities
    cities = pd.read_csv(CITIES, dtype=str)
    # Ø§Ù†ÙˆØ§Ø¹ Ø¹Ø¯Ø¯ÛŒ
    for col in ("lat","lon","population"):
        if col in cities.columns:
            cities[col] = pd.to_numeric(cities[col], errors="coerce")
    cities["city_name_norm"] = cities["city_name"].map(norm_text)

    # 2) ISTAT datasets
    hh   = norm_df(load_or_empty(HH),   "territory_name")
    homes= norm_df(load_or_empty(HOMES),"territory_name")
    fams = norm_df(load_or_empty(FAMS), "territory_name")
    comm = norm_df(load_or_empty(COMM), "territory_name")

    # ØªØ¨Ø¯ÛŒÙ„ Ø§Ø¹Ø¯Ø§Ø¯
    if "households" in hh.columns:
        hh["households"] = pd.to_numeric(hh["households"], errors="coerce")
        hh = hh.groupby("territory_name_norm", as_index=False)["households"].max()

    if {"dwellings_total","dwellings_occupied","occupied_share"}.issubset(homes.columns):
        homes["dwellings_total"]    = pd.to_numeric(homes["dwellings_total"], errors="coerce")
        homes["dwellings_occupied"] = pd.to_numeric(homes["dwellings_occupied"], errors="coerce")
        homes["occupied_share"]     = pd.to_numeric(homes["occupied_share"], errors="coerce")
        homes = homes.groupby("territory_name_norm", as_index=False).agg({
            "dwellings_total":"max","dwellings_occupied":"max","occupied_share":"max"
        })

    if {"families_total","families_3plus_share","avg_family_size_from_istat"}.issubset(fams.columns):
        fams["families_total"] = pd.to_numeric(fams["families_total"], errors="coerce")
        fams["families_3plus_share"] = pd.to_numeric(fams["families_3plus_share"], errors="coerce")
        fams["avg_family_size_from_istat"] = pd.to_numeric(fams["avg_family_size_from_istat"], errors="coerce")
        fams = fams.groupby("territory_name_norm", as_index=False).agg({
            "families_total":"max","families_3plus_share":"max","avg_family_size_from_istat":"max"
        })

    if {"resident_population","commuting_population","commuting_ratio"}.issubset(comm.columns):
        comm["resident_population"]  = pd.to_numeric(comm["resident_population"], errors="coerce")
        comm["commuting_population"] = pd.to_numeric(comm["commuting_population"], errors="coerce")
        comm["commuting_ratio"]      = pd.to_numeric(comm["commuting_ratio"], errors="coerce")
        comm = comm.groupby("territory_name_norm", as_index=False).agg({
            "resident_population":"max","commuting_population":"max","commuting_ratio":"max"
        })
        # Ø§Ø³Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø±Ø§ ÙˆØ§Ø¶Ø­â€ŒØªØ± Ú©Ù†ÛŒÙ…
        comm = comm.rename(columns={
            "resident_population":"resident_population_istat"
        })

    # 3) Ù…Ø±Ø¬ Ù†Ø§Ù…â€ŒÙ…Ø­ÙˆØ± (left) Ø¨Ø§ Ú¯Ø²Ø§Ø±Ø´ unmatched
    merged = cities.copy()
    # households
    if not hh.empty:
        merged = merged.merge(hh, left_on="city_name_norm", right_on="territory_name_norm", how="left")
        merged = merged.drop(columns=["territory_name_norm"], errors="ignore")
    # homes
    if not homes.empty:
        merged = merged.merge(homes, left_on="city_name_norm", right_on="territory_name_norm", how="left")
        merged = merged.drop(columns=["territory_name_norm"], errors="ignore")
    # families
    if not fams.empty:
        merged = merged.merge(fams, left_on="city_name_norm", right_on="territory_name_norm", how="left")
        merged = merged.drop(columns=["territory_name_norm"], errors="ignore")
    # commuting
    if not comm.empty:
        merged = merged.merge(comm, left_on="city_name_norm", right_on="territory_name_norm", how="left")
        merged = merged.drop(columns=["territory_name_norm"], errors="ignore")

    # 4) Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ú©Ù…Ú©ÛŒ
    # avg_family_size (fallback): population / households
    if "households" in merged.columns:
        merged["avg_family_size"] = (merged["population"] / merged["households"]).where(merged["households"]>0)

    # 5) Ø®Ø±ÙˆØ¬ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
    out_cols = [
        "city_id","city_name","region","lat","lon","population",
        "households","avg_family_size","families_total","families_3plus_share","avg_family_size_from_istat",
        "dwellings_total","dwellings_occupied","occupied_share",
        "resident_population_istat","commuting_population","commuting_ratio"
    ]
    for c in out_cols:
        if c not in merged.columns: merged[c] = pd.NA

    merged[out_cols].to_csv(OUT, index=False)
    print(f"âœ“ Saved: {OUT}  rows={len(merged)}")

    # Ú¯Ø²Ø§Ø±Ø´ unmatchedâ€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… (Ø´Ù‡Ø±Ù‡Ø§ÛŒ Ù¾Ø±Ø¬Ù…Ø¹ÛŒØª Ú©Ù‡ household Ù†Ø¯Ø§Ø±Ù†Ø¯)
    rep = merged[merged["households"].isna()][["city_id","city_name","region","population"]].copy()
    rep = rep.sort_values("population", ascending=False).head(500)
    rep_path = os.path.join(REPORT, "unmatched_top500.csv")
    rep.to_csv(rep_path, index=False)
    print(f"â†ª unmatched report: {rep_path}  rows={len(rep)}")

if __name__ == "__main__":
    main()
```

### Ø§Ø¬Ø±Ø§

```
source ~/myenvironments/Tourism/bin/activate
python /home/tahmast/Projects/Tourism/scripts/merge_cities_all.py
```

**Ø§Ù†ØªØ¸Ø§Ø± Ø®Ø±ÙˆØ¬ÛŒ:**

- `data/curated/cities_it_enriched_full.csv`
- `data/curated/reports/unmatched_top500.csv`



## Ø¨Ø¹Ø¯Ø´ Ú†ÛŒØŸ

- Ø§Ú¯Ø± Ù¾ÙˆØ´Ø´ `households` ÛŒØ§ Ø¨Ù‚ÛŒÙ‡ Ù¾Ø§ÛŒÛŒÙ† Ø¨ÙˆØ¯ØŒ Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒÙ… ÛŒÚ© **Ù„ØºØªâ€ŒÙ†Ø§Ù…Ù‡Ù” Ù†Ú¯Ø§Ø´Øª Ù†Ø§Ù…** Ø¨Ø³Ø§Ø²ÛŒÙ… (Ù…Ø«Ø§Ù„: `{"Reggio nell'Emilia": "Reggio Emilia"}`) Ùˆ Ù‚Ø¨Ù„ Ø§Ø² merge Ø§Ø¹Ù…Ø§Ù„ Ú©Ù†ÛŒÙ… ØªØ§ Ù…Ú†â€ŒÙ‡Ø§ Ø²ÛŒØ§Ø¯ØªØ± Ø¨Ø´Ù†.
- ÛŒØ§ Ø§Ú¯Ø± Ø®ÙˆØ§Ø³ØªÛŒØŒ Ù…Ø±Ø­Ù„Ù‡Ù” Ø¯ÙˆÙ… fuzzy matching (RapidFuzz) ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ **top-N Ø´Ù‡Ø±Ù‡Ø§ÛŒ Ù¾Ø±Ø¬Ù…Ø¹ÛŒØª unmatched** Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ù….

Ù‡Ø± Ù…ÙˆÙ‚Ø¹ Ø§ÛŒÙ† Ù…Ø±Ø¬ Ù†Ù‡Ø§ÛŒÛŒ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯ØŒ Ûµâ€“Û±Û° Ø®Ø· Ø§ÙˆÙ„ `cities_it_enriched_full.csv` Ø±Ùˆ Ø¨Ø¯Ù‡Ø› Ø¨Ø¹Ø¯Ø´ Ù…ÛŒâ€ŒØ±ÛŒÙ… Ø³Ø±Ø§Øº Ù…Ø±Ø­Ù„Ù‡Ù” Ø¨Ø¹Ø¯ÛŒ:
 **Ø³Ø§Ø®Øª `configs/cities.yaml` Ùˆ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ) `configs/hotels.yaml` ÙˆØ§Ù‚Ø¹ÛŒ** Ùˆ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ProducerÙ‡Ø§ÛŒ Faker (seasonality/weights) ğŸ’ª



## Ø³Ù†Ø§Ø±ÛŒÙˆ

Ø¯Ø± Ø§ÛŒÙ† Ø³Ù†Ø§Ø±ÛŒÙˆØŒ Ù‡Ø¯Ù Ø³Ø§Ø®ØªÙ† ÛŒÚ© **Pipeline ØªØ­Ù„ÛŒÙ„ÛŒ ÙˆØ§Ù‚Ø¹â€ŒÙ†Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ Ø§ÛŒØªØ§Ù„ÛŒØ§** Ø§Ø³Øª Ú©Ù‡ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø¨Ù‡â€ŒÙˆØ§Ù‚Ø¹ÛŒ (Ø´Ù‡Ø±Ù‡Ø§ØŒ ÙØ±ÙˆØ¯Ú¯Ø§Ù‡â€ŒÙ‡Ø§ØŒ Ù‡ØªÙ„â€ŒÙ‡Ø§ØŒ ÙØµÙ„â€ŒÙ‡Ø§ØŒ Ø¬Ù…Ø¹ÛŒØª Ùˆ Ø¢Ø¨â€ŒÙˆÙ‡ÙˆØ§) Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ Ø¬Ø±ÛŒØ§Ù† Ø¯Ø§Ø¯Ù‡ Ø±Ø§ Ø§Ø² Ù…Ø±Ø­Ù„Ù‡â€ŒÛŒ ØªÙˆÙ„ÛŒØ¯ ØªØ§ Ù…ØµÙˆØ±Ø³Ø§Ø²ÛŒ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ù†Ø¯. Ø¯Ø± Ø§ÛŒÙ† Ø¬Ø±ÛŒØ§Ù†ØŒ **Ø³Ù‡ Producer** Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø±Ø²Ø±Ùˆ Ù‡ØªÙ„ØŒ Ù¾Ø±ÙˆØ§Ø²Ù‡Ø§ Ùˆ ÙˆØ¶Ø¹ÛŒØª Ø¢Ø¨â€ŒÙˆÙ‡ÙˆØ§ Ø±Ø§ Ø¨Ù‡â€ŒØµÙˆØ±Øª Ù‡Ù…â€ŒØ²Ù…Ø§Ù† ØªÙˆÙ„ÛŒØ¯ Ú©Ø±Ø¯Ù‡ Ùˆ Ø§Ø² Ø·Ø±ÛŒÙ‚ **Kafka** Ø¨Ù‡ Ø³ÛŒØ³ØªÙ… Ù…Ù†ØªÙ‚Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯. Kafka Ø¨Ù‡â€ŒØ¹Ù†ÙˆØ§Ù† Ø³ØªÙˆÙ† ÙÙ‚Ø±Ø§Øª Ù…Ø¹Ù…Ø§Ø±ÛŒØŒ Ù…Ø³Ø¦ÙˆÙ„ ØµÙâ€ŒØ¨Ù†Ø¯ÛŒ Ùˆ Ù¾Ø®Ø´ Ù…Ø·Ù…Ø¦Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨ÛŒÙ† Ø§Ø¬Ø²Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø§Ø³Øª.

Ø¯Ø± Ù…Ø±Ø­Ù„Ù‡â€ŒÛŒ Ø¨Ø¹Ø¯ØŒ **Apache Spark** (Ù‡Ù… Ø¯Ø± Ø­Ø§Ù„Øª Ø§Ø³ØªØ±ÛŒÙ… Ùˆ Ù‡Ù… Batch) Ø§ÛŒÙ† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø±Ø¯Ù‡ØŒ Ø±ÙˆÛŒØ¯Ø§Ø¯Ù‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ù‡Ø± Ùˆ Ø²Ù…Ø§Ù† ØªØ±Ú©ÛŒØ¨ Ùˆ Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒÛŒ Ù…Ø§Ù†Ù†Ø¯ Ù†Ø±Ø® Ø§Ø´ØºØ§Ù„ØŒ Ù„ØºÙˆØŒ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù‚ÛŒÙ…Øª Ùˆ ØªÙ‚Ø§Ø¶Ø§ÛŒ Ú¯Ø±Ø¯Ø´Ú¯Ø± Ø±Ø§ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ Ø¨Ù‡â€ŒØµÙˆØ±Øª **Parquet** (Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø³Ù†Ú¯ÛŒÙ† Ùˆ Ù†Ú¯Ù‡â€ŒØ¯Ø§Ø±ÛŒ Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª) Ùˆ Ù‡Ù…â€ŒØ²Ù…Ø§Ù† Ø¯Ø± **PostgreSQL** (Ø¨Ø±Ø§ÛŒ Ø³Ø±Ùˆ Ø³Ø±ÛŒØ¹ Ø¨Ù‡ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯Ù‡Ø§) Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯. Ø¯Ø± Ù¾Ø§ÛŒØ§Ù†ØŒ **Grafana** Ùˆ **Power BI** Ø¨Ø§ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Postgres ÛŒØ§ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ParquetØŒ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ø²Ù†Ø¯Ù‡ Ùˆ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯ ØªØ§ Ù…Ø¯ÛŒØ±Ø§Ù† Ø¨ØªÙˆØ§Ù†Ù†Ø¯ Ø±ÙˆÙ†Ø¯ Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒØŒ ÙØµÙ„â€ŒÙ‡Ø§ÛŒ Ù¾Ø±ØªØ±Ø§ÙÛŒÚ© Ùˆ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ù†Ø§Ø·Ù‚ Ù…Ø®ØªÙ„Ù Ø±Ø§ Ø¯Ø± Ù„Ø­Ø¸Ù‡ Ø¨Ø¨ÛŒÙ†Ù†Ø¯.

Ø§ÛŒÙ† Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ú©ÙˆÚ†Ú©ÛŒ Ø§Ø² ÛŒÚ© **Ø³ÛŒØ³ØªÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ…Ø­ÙˆØ± Ø¯Ø± Ù…Ù‚ÛŒØ§Ø³ ÙˆØ§Ù‚Ø¹ÛŒ** Ø§Ø³ØªØ› Ø§Ø² ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡ ØªØ§ Ù¾Ø±Ø¯Ø§Ø²Ø´ØŒ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ù…ØµÙˆØ±Ø³Ø§Ø²ÛŒ â€” Ù‡Ù…Ù‡ Ø¯Ø± ÛŒÚ© Ú†Ø±Ø®Ù‡â€ŒÛŒ Ú©Ø§Ù…Ù„ Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡.

```mermaid
flowchart LR
subgraph REF["Ø§Ø¨Ø¹Ø§Ø¯ Ù…Ø±Ø¬Ø¹"]
  CITIES["cities.yaml â†’ ref.city.v1 (compact)<br/>+ Postgres dim_cities"];
  HOTELS["hotels.yaml â†’ ref.hotel.v1<br/>+ Postgres dim_hotels"];
end;

subgraph P["Producers (Faker)"]
  BK["bookings_producer.py<br/>booking.events.v1"];
  FL["flights_producer.py<br/>flight.events.v1"];
  WX["weather_producer.py<br/>weather.events.v1"];
end;

subgraph K["Kafka / Redpanda"]
  BKT["booking.events.v1<br/>3â€“6 partitions"];
  FLT["flight.events.v1<br/>3â€“6 partitions"];
  WXT["weather.events.v1<br/>3 partitions"];
  DQ["dlq.bad_schema"];
end;

subgraph SP["Spark Structured Streaming"]
  BR["Bronze: raw ingestion"];
  SL["Silver: cleansing & joins<br/>(Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒØŒ watermark, dedup)"];
  GL["Gold: city_day_kpis<br/>+ city_month_kpis"];
end;

subgraph ST["Storage"]
  PQ["Parquet<br/>bronze/silver/gold"];
  PG["Postgres<br/>serving marts"];
end;

subgraph VIS["Serving & BI"]
  GR["Grafana (JSON Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯)"];
  PB["Power BI (.pbix Ø§Ø®ØªÛŒØ§Ø±ÛŒ)"];
end;

CITIES -->|load once| BKT;
HOTELS -->|load once| FLT;

P --> BKT;
P --> FLT;
P --> WXT;

BKT --> BR;
FLT --> BR;
WXT --> BR;

BR --> SL;
SL -->|join dim_city/hotel + weather lags| GL;

GL --> PQ;
GL --> PG;

PG --> GR;
PQ --> PB;

%% Ø®Ø·Ø§ÛŒ Ø¹Ù…Ø¯ÛŒ
BK -. "0.5% bad schema" .-> DQ;
FL -. "1% late events" .-> BR;

```



## 1) ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¬Ø¹ (Static/Curated)

- **`cities_it_enriched_full.csv`** + Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ (`configs/*.yaml`): Ø´Ù‡Ø±Ù‡Ø§/ÙØ±ÙˆØ¯Ú¯Ø§Ù‡â€ŒÙ‡Ø§/Ù‡ØªÙ„â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒØŒ Ø¨Ø§ ÙˆØ²Ù†â€ŒØ¯Ù‡ÛŒ Ø¬Ù…Ø¹ÛŒØªØŒ ÙØµÙ„ØŒ Ø¢Ø¨â€ŒÙˆÙ‡ÙˆØ§ØŒ Ù†Ø³Ø¨Øª commute Ùˆâ€¦
- Ø§ÛŒÙ†â€ŒÙ‡Ø§ Â«Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹â€ŒÙ†Ù…Ø§Â» Ø±Ø§ Ø¨Ù‡ ProducerÙ‡Ø§ Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯ ØªØ§ Ø¯Ø§Ø¯Ù‡Ù” ÙÛŒÚ© ÙˆÙ„ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨Ø³Ø§Ø²Ù†Ø¯.

## 2) Producers (ØªÙˆÙ„ÛŒØ¯ Ø¬Ø±ÛŒØ§Ù† Ø±ÙˆÛŒØ¯Ø§Ø¯)

- **`flights_producer`**: Ù¾Ø±ÙˆØ§Ø²Ù‡Ø§ Ùˆ Ø±ÙˆÛŒØ¯Ø§Ø¯Ù‡Ø§ÛŒ Ù¾Ø±ÙˆØ§Ø²ÛŒ (arrival, delay, cancel) Ø±Ø§ Ø·Ø¨Ù‚ ÙØµÙ„/Ø´Ù‡Ø±/ÙØ±ÙˆØ¯Ú¯Ø§Ù‡ ØªÙˆÙ„ÛŒØ¯ Ùˆ Ø¨Ù‡ ØªØ§Ù¾ÛŒÚ© **`flights`** Ù…ÛŒâ€ŒÙØ±Ø³ØªØ¯.
- **`bookings_producer`**: Ø±Ø²Ø±Ùˆ Ù‡ØªÙ„ (check-in/outØŒ ADR proxyØŒ ØªØ¹Ø¯Ø§Ø¯ Ù…ÛŒÙ‡Ù…Ø§Ù†ØŒ Ú©Ø§Ù†Ø§Ù„ ÙØ±ÙˆØ´) Ø±Ø§ Ø¨Ù‡ **`bookings`** Ù…ÛŒâ€ŒÙØ±Ø³ØªØ¯.
- **`weather_producer`**: Ø¢Ø¨â€ŒÙˆÙ‡ÙˆØ§ (Ø¯Ù…Ø§/Ø¨Ø§Ø±Ø´/Ø´Ø±Ø§ÛŒØ·) Ù‡Ù…â€ŒØªØ±Ø§Ø² Ø¨Ø§ Ø´Ù‡Ø±/ØªØ§Ø±ÛŒØ® Ø±Ø§ Ø¨Ù‡ **`weather`** Ù…ÛŒâ€ŒÙØ±Ø³ØªØ¯.
- Ù‡Ù…Ù‡ Ø¨Ø§ **Ú©Ø¯Ú¯Ø°Ø§Ø±ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø± (JSON/Avro)** Ùˆ **Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ù¾Ø§ÛŒØ¯Ø§Ø±** (Ù…Ø«Ù„ `city_id|date` ÛŒØ§ `iata+ts`) ØªØ§ Ø¨Ø¹Ø¯Ø§Ù‹ join/aggregation Ù¾Ø§ÛŒØ¯Ø§Ø± Ø§Ù†Ø¬Ø§Ù… Ø´ÙˆØ¯.

## 3) Kafka (Ù„Ø§ÛŒÙ‡ Ø§Ø³ØªØ±ÛŒÙ…)

- Ø³Ù‡ **Topic**â€Œ: `flights`, `bookings`, `weather` Ø¨Ø§ Ù¾Ø§Ø±ØªÛŒØ´Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ú©Ù„ÛŒØ¯ Ø´Ù‡Ø±/ØªØ§Ø±ÛŒØ® â†’ **Ù…Ù‚ÛŒØ§Ø³â€ŒÙ¾Ø°ÛŒØ±ÛŒ** Ùˆ **ØªØ±ØªÛŒØ¨ Ù†Ø³Ø¨ÛŒ**.
- Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ù…Ù†Ø§Ø³Ø¨ **retention** Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ù¾Ø®Ø´ (replay) Ùˆ **consumer group** Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ±ÛŒÙ…â€ŒÙ‡Ø§.

## 4) Spark Processing (Streaming + Batch)

- **Streaming Job (`spark/streaming_city_kpis.py`)**
  - Ù…ØµØ±Ù Ø³Ù‡ ØªØ§Ù¾ÛŒÚ© Ùˆ **join Ø¨Ø§ Ù¾Ù†Ø¬Ø±Ù‡Ù” Ø²Ù…Ø§Ù†ÛŒ** (event-time) + **Watermark** Ø¨Ø±Ø§ÛŒ Ø±ÙˆÛŒØ¯Ø§Ø¯Ù‡Ø§ÛŒ Ø¯ÛŒØ±Ø±Ø³.
  - **Dedup** Ø¨Ø§ Ú©Ù„ÛŒØ¯ Ø±ÙˆÛŒØ¯Ø§Ø¯ + Ø²Ù…Ø§Ù†ØŒ Ùˆ **Stateful aggregations** Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®Øª KPI Ø±ÙˆØ²Ø§Ù†Ù‡Ù” Ø´Ù‡Ø± (`arrivals_today`, `cancel_rate`, `occupancy proxy`, `ADR proxy` Ùˆ â€¦).
  - Ø®Ø±ÙˆØ¬ÛŒ Ø§Ø³ØªØ±ÛŒÙ… Ø¨Ù‡ **Bronze/Silver/Gold (Parquet)** Ùˆ Ù‡Ù…Ø²Ù…Ø§Ù† **Upsert** Ø¨Ù‡ **Postgres** (Ø¬Ø¯ÙˆÙ„ fact Ø±ÙˆØ²Ø§Ù†Ù‡).
- **Batch Job (`spark/batch_monthly_rollup.py`)**
  - Ø±ÙˆÙ„â€ŒØ¢Ù¾ Ù…Ø§Ù‡Ø§Ù†Ù‡ (monthly) Ø§Ø² Gold Ø±ÙˆØ²Ø§Ù†Ù‡ØŒ Ù…Ø­Ø§Ø³Ø¨Ù‡Ù” **seasonality indices**, Ù†Ø±Ø®â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù‡Ø§Ù†Ù‡ØŒ percentiles Ùˆâ€¦
  - Ù†ÙˆØ´ØªÙ† Ø¨Ù‡ **Parquet (gold/monthly)** Ùˆ **Ø¬Ø¯Ø§ÙˆÙ„ Ø®Ù„Ø§ØµÙ‡Ù” Postgres**.

## 5) Data Lakehouse (Files)

- **Parquet Ù„Ø§ÛŒÙ‡â€ŒÙ…Ù†Ø¯**:
  - **Bronze**: Ø®Ø§Ù…Ù ØªÙ…ÛŒØ²Ø´Ø¯Ù‡ (Ø§Ø² Kafka)
  - **Silver**: enriched/cleaned Ø¨Ø§ join Ù…Ø±Ø¬Ø¹
  - **Gold**: KPIÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡/Ù…Ø§Ù‡Ø§Ù†Ù‡
- **Ù¾Ø§Ø±ØªÛŒØ´Ù†â€ŒØ¨Ù†Ø¯ÛŒ**: `dt=YYYY-MM-DD/region/city` Ø¨Ø±Ø§ÛŒ Ø§Ø³Ú©Ù† Ø³Ø±ÛŒØ¹.
- Ù…Ø²ÛŒØª: Ù…Ù†Ø§Ø¨Ø¹ Ú¯Ø²Ø§Ø±Ø´â€ŒÚ¯ÛŒØ±ÛŒ Ø¢ÙÙ„Ø§ÛŒÙ†/ØªØ­Ù„ÛŒÙ„ÛŒ Ù¾Ø±Ø­Ø¬Ù… Ø¨Ø¯ÙˆÙ† ÙØ´Ø§Ø± Ø¨Ù‡ Postgres.

## 6) Postgres (Serving Layer Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯)

- **Ø¬Ø¯Ø§ÙˆÙ„ fact/dim** Ø¨Ø±Ø§ÛŒ Ù…ØµØ±Ù Ø³Ø±ÛŒØ¹ BI:
  - `fact_city_day_kpis(city_id, date, arrivals, cancellations, occ_proxy, adr_proxy, â€¦)`
  - Ø§Ø¨Ø¹Ø§Ø¯: `dim_city`, `dim_airport`, `dim_date`
- **Upsert/merge** Ø§Ø² Ø§Ø³ØªØ±ÛŒÙ…Ø› **Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø±ÙˆÛŒ (`city_id`, `date`)**Ø› (Ø§Ø®ØªÛŒØ§Ø±ÛŒ) `postgis` Ø¨Ø±Ø§ÛŒ Ù†Ù‚Ø´Ù‡ØŒ `timescaledb` Ø¨Ø±Ø§ÛŒ time-series.

## 7) Visualization (Grafana / Power BI)

- **Grafana** (Real-time):
  - Ù¾Ù†Ù„â€ŒÙ‡Ø§ÛŒ lag Ù…ØµØ±Ùâ€ŒÚ©Ù†Ù†Ø¯Ù‡ØŒ `msgs/sec`, ØªØ§Ø®ÛŒØ± Ø±ÙˆÛŒØ¯Ø§Ø¯Ù‡Ø§ØŒ KPI Ø±ÙˆØ²Ø§Ù†Ù‡ØŒ **Geo map** Ø±ÙˆÛŒ `dim_city (lat, lon)` + KPI.
- **Power BI** (ØªØ­Ù„ÛŒÙ„ Ùˆ Ú¯Ø²Ø§Ø±Ø´ Aggregated):
  - Ø±ÙˆÙ„â€ŒØ¢Ù¾ Ù…Ø§Ù‡Ø§Ù†Ù‡/ÙØµÙ„ÛŒØŒ Ù…Ù‚Ø§ÛŒØ³Ù‡Ù” Ù…Ù†Ø§Ø·Ù‚/Ø´Ù‡Ø±ÛŒØŒ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ø¸Ø±ÙÛŒØª/ØªÙ‚Ø§Ø¶Ø§.

## 8) Ú©ÛŒÙÛŒØª Ø¯Ø§Ø¯Ù‡ Ùˆ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ

- **Schema Registry** (Ø§Ø®ØªÛŒØ§Ø±ÛŒ ÙˆÙ„ÛŒ ØªÙˆØµÛŒÙ‡â€ŒØ´Ø¯Ù‡) Ø¨Ø±Ø§ÛŒ ØªÚ©Ø§Ù…Ù„ schema Ùˆ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø´Ú©Ø³ØªÙ† pipeline.
- **Checkpoints** Ø§Ø³ØªØ±ÛŒÙ… Ø¯Ø± HDFS/FS Ø¨Ø±Ø§ÛŒ **exactly-once-ish** (idempotent sinks + dedup).
- **Late-arrival handling** Ø¨Ø§ watermark Ùˆ **ØªØµØ­ÛŒØ­ KPI** (recompute Ù¾Ù†Ø¬Ø±Ù‡Ù” Ø±ÙˆØ²Ø§Ù†Ù‡ Ù…Ø­Ø¯ÙˆØ¯).
- **Monitoring**: Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Kafka/Spark/Postgres Ø¯Ø± Grafana (Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ø³Ù„Ø§Ù…Øª Pipeline).



1. Ù…Ø­ÛŒØ· Ùˆ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡

```
~/tools/confluent-8.0.2/
~/Projects/Tourism/
    â”œâ”€â”€ producers/
    â”‚    â””â”€â”€ orchestrator_producers.py
    â””â”€â”€ data/curated/
         â”œâ”€â”€ hotels_clean.csv
         â”œâ”€â”€ airports_it.csv
         â””â”€â”€ cities_it_enriched_cleaned.csv

```

2. Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Kafka Ø¯Ø± Ø­Ø§Ù„Øª KRaft

### ÙØ§ÛŒÙ„ ØªÙ†Ø¸ÛŒÙ…Ø§Øª:

```
etc/kafka/server.properties
```

```
process.roles=broker,controller
node.id=1
controller.listener.names=CONTROLLER
listeners=PLAINTEXT://:9092,CONTROLLER://:9093
inter.broker.listener.name=PLAINTEXT
controller.quorum.voters=1@localhost:9093
log.dirs=/tmp/kraft-combined-logs
num.partitions=1
auto.create.topics.enable=true
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1

```

## 3. Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ KRaft

```
cd ~/tools/confluent-8.0.2
rm -rf /tmp/kraft-combined-logs

export KAFKA_HEAP_OPTS="-Xms256m -Xmx512m"
CLUSTER_ID=$(bin/kafka-storage.sh random-uuid)
echo $CLUSTER_ID


bin/kafka-storage.sh format -t $CLUSTER_ID -c etc/kafka/server.properties
bin/kafka-server-start.sh etc/kafka/server.properties
```

âœ… Ù†Ú©ØªÙ‡: Ø§Ø² `--standalone` Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù† Ú†ÙˆÙ† `controller.quorum.voters` Ø³Øª Ø´Ø¯Ù‡.

confluent ''.sh" Ù†Ø¯Ø§Ø±Ø¯  Ù†Ø¨Ø§ÛŒØ¯ Ø¨Ø°Ø§Ø±ÛŒ



##  4. Ø³Ø§Ø®Øª ØªØ§Ù¾ÛŒÚ©â€ŒÙ‡Ø§

```
bin/kafka-topics.sh --list --bootstrap-server localhost:9092

bin/kafka-topics.sh --bootstrap-server localhost:9092 \
  --create --topic flight.events.v1 --partitions 1 --replication-factor 1

bin/kafka-topics.sh --bootstrap-server localhost:9092 \
  --create --topic booking.events.v1 --partitions 1 --replication-factor 1

bin/kafka-topics.sh --bootstrap-server localhost:9092 \
  --create --topic weather.events.v1 --partitions 1 --replication-factor 1
```

confluent ''.sh" Ù†Ø¯Ø§Ø±Ø¯  Ù†Ø¨Ø§ÛŒØ¯ Ø¨Ø°Ø§Ø±ÛŒ

## 5. ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡ (Python Producer)

ÙØ§ÛŒÙ„: `producers/orchestrator_producers.py`

ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†Ø³Ø®Ù‡ Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡:

- Ø³Ø§Ø²Ú¯Ø§Ø± Ø¨Ø§ Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ø¶Ø¹ÛŒÙ (8GB RAM)
- Ø¯Ø§Ø±Ø§ÛŒ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡â€ŒÚ¯ÛŒØ±ÛŒ (`--sample-cities`, `--sample-hotels`, â€¦)
- Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² `librdkafka` Ø¨Ø§ `compression.lz4`
- Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ§Ù†Ø§ Ø¨Ø±Ø§ÛŒ Ø´Ù…Ø§Ø±Ø´ ØªÙˆÙ„ÛŒØ¯Ø§Øª Ø¯Ø± Ù‡Ø± Ø±ÙˆØ²
- Ù…Ø³ÛŒØ± ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§ Ø§Ø² Ù¾Ø§Ø±Ø§Ù…ØªØ± `--base` Ù‚Ø§Ø¨Ù„ ØªÙ†Ø¸ÛŒÙ… Ø§Ø³Øª

#### orchestrator_producers.py

```
#!/usr/bin/env python3
# producers/orchestrator_producers.py
"""
Unified generator for flights, bookings and weather.

Examples:
  # timewarp: simulate N days quickly (light)
  python producers/orchestrator_producers.py --mode timewarp --days 7 --timewarp 500 --rate 800

  # realtime: slow continuous stream
  python producers/orchestrator_producers.py --mode realtime --rate 1
"""

import argparse, random, uuid, json, math, time
from datetime import datetime, timedelta, date, timezone
from pathlib import Path
import pandas as pd
import numpy as np
from confluent_kafka import Producer

# --------- Helpers ----------
def now_iso(ts=None):
    return (ts or datetime.now(timezone.utc)).strftime("%Y-%m-%dT%H:%M:%SZ")

def sample_lead_time(city_type_factor):
    # mixture: business (exp dist mean 5), leisure (normal mean 30)
    if random.random() < 0.35 * city_type_factor:  # busier cities have more business
        return max(0, int(random.expovariate(1/5)))
    else:
        return max(1, int(random.gauss(30, 20)))

def seasonality(city_row, sim_date):
    m = sim_date.month
    base = 1.0
    # peak months (string "[6,7,8]" or list)
    if "peak_months" in city_row and isinstance(city_row["peak_months"], list):
        if m in city_row["peak_months"]:
            base *= 1.4
    # weekend bump
    if sim_date.weekday() >= 5:
        base *= 1.15
    # population scaling
    pop = float(city_row.get("population", 10000) or 10000)
    base *= (1 + math.log1p(pop)/12.0)
    return base

def make_trace():
    return uuid.uuid4().hex

# --------- Load data ----------
def load_inputs(base):
    base = Path(base)
    hotels = pd.read_csv(base/"data/curated/hotels_clean.csv", dtype=str)
    airports = pd.read_csv(base/"data/curated/airports_it.csv", dtype=str)
    cities = pd.read_csv(base/"data/curated/cities_it_enriched_cleaned.csv", dtype=str)

    # minimal casting
    if "population" not in cities.columns:
        cities["population"] = 10000
    cities["population"] = pd.to_numeric(cities["population"], errors="coerce").fillna(10000)

    # Build mapping IATA->city_name (optional)
    if "airport_code" in airports.columns and "city_name" in airports.columns:
        airports["iata"] = airports["airport_code"].astype(str)
        iata_to_city = airports.set_index("airport_code")["city_name"].to_dict()
    else:
        iata_to_city = {}

    return hotels, airports, cities, iata_to_city

# --------- Delivery report callback ----------
def _dr_cb(err, msg):
    if err:
        print("Delivery failed:", err)
    # else:
    #     print(f"Delivered {msg.topic()}[{msg.partition()}]@{msg.offset()}")

# --------- Core generators ----------
class Simulator:
    def __init__(self, hotels, airports, cities, iata_map, producer, topics):
        self.hotels = hotels
        self.airports = airports
        self.cities = cities
        self.iata_map = iata_map
        self.producer = producer
        self.topics = topics

        # counters for per-day diagnostics
        self.cnt_weather = 0
        self.cnt_flights = 0
        self.cnt_bookings = 0

        # Precompute city meta
        self.city_meta = {}
        for _, r in cities.iterrows():
            cid = str(r["city_id"])
            pop = float(r.get("population", 10000) or 10000)
            self.city_meta[cid] = {
                "population": pop,
                "row": r.to_dict(),
                "hotels": hotels[hotels["city_id"] == cid].to_dict("records")
            }

    def emit(self, topic, key, value):
        payload = json.dumps(value).encode("utf-8")
        keyb = str(key).encode("utf-8")
        try:
            self.producer.produce(topic, payload, key=keyb, on_delivery=_dr_cb)
            # poll>0 ØªØ§ callback Ù‡Ø§ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ø´ÙˆÙ†Ø¯
            self.producer.poll(0)
        except BufferError as e:
            print("Local queue is full, backing off...", e)
            self.producer.poll(0.5)
            self.producer.produce(topic, payload, key=keyb, on_delivery=_dr_cb)

    def gen_weather_for_date(self, sim_date):
        for cid, meta in self.city_meta.items():
            row = meta["row"]
            month = sim_date.month
            t_base = 5 + (month/12.0)*20 + random.gauss(0, 3)
            precip = max(0, random.gauss(2 + (12-month)/6.0, 5))
            condition = "clear"
            if precip > 10:
                condition = random.choice(["rain", "storm"])
            elif precip > 2:
                condition = "rain"

            is_peak = False
            if "peak_months" in row and isinstance(row["peak_months"], str):
                try:
                    peaks = [int(x) for x in row["peak_months"].strip("[]").split(",") if x]
                    is_peak = sim_date.month in peaks
                except Exception:
                    is_peak = False

            payload = {
                "schema_version": "v1",
                "event_type": "daily_weather",
                "event_ts": now_iso(datetime(sim_date.year, sim_date.month, sim_date.day, 0, 0, tzinfo=timezone.utc)),
                "ingest_ts": now_iso(),
                "trace_id": make_trace(),
                "producer": "faker",
                "city_id": cid,
                "date": sim_date.isoformat(),
                "t_min": round(t_base - random.uniform(2, 6), 1),
                "t_max": round(t_base + random.uniform(2, 6), 1),
                "precip_mm": round(precip, 1),
                "wind_kph": round(max(0, random.gauss(12, 8)), 1),
                "humidity": round(min(1.0, max(0, random.gauss(0.6, 0.15))), 2),
                "condition": condition,
                "is_peak_season": is_peak,
                "holiday_flag": False
            }
            self.emit(self.topics["weather"], f"{cid}|{sim_date.isoformat()}", payload)
            self.cnt_weather += 1

    def gen_flights_for_date(self, sim_date):
        for _, ap in self.airports.iterrows():
            iata = ap.get("airport_code")
            city_name = ap.get("city_name")
            # resolve city
            if city_name:
                m = self.cities[
                    self.cities["city_name"]
                    .fillna("")
                    .str.lower()
                    .str.contains(str(city_name).lower(), regex=False)
                ]
                if len(m) > 0:
                    city_row = m.iloc[0].to_dict()
                    city_id = str(city_row["city_id"])
                else:
                    city_id = random.choice(list(self.city_meta.keys()))
                    city_row = self.city_meta[city_id]["row"]
            else:
                city_id = random.choice(list(self.city_meta.keys()))
                city_row = self.city_meta[city_id]["row"]

            s = seasonality(city_row, sim_date)
            pop = float(city_row.get("population", 10000))
            expected_arrivals = max(1, int((pop / 2000.0) * s))

            for _ in range(expected_arrivals):
                flight_id = f"FA{random.randint(100, 9999)}"
                seats = random.choice([100, 150, 180, 220])
                load = min(1.0, max(0.3, random.gauss(0.7, 0.12)))
                weather_factor = random.random() * 0.15
                congestion = random.random() * 0.15
                delay = int(random.gauss(5, 10) + (weather_factor + congestion) * 60)
                if random.random() < 0.01 + weather_factor * 0.5:
                    status = "cancelled"
                    delay = None
                else:
                    status = "arrived"
                sched_dep = datetime(sim_date.year, sim_date.month, sim_date.day,
                                     random.randint(0, 23), random.choice([0, 15, 30, 45]), tzinfo=timezone.utc)
                sched_arr = sched_dep + timedelta(minutes=random.randint(40, 180))
                payload = {
                    "schema_version": "v1",
                    "event_type": "flight_arrival",
                    "event_ts": now_iso(sched_arr + timedelta(minutes=(delay or 0))),
                    "ingest_ts": now_iso(),
                    "trace_id": make_trace(),
                    "producer": "faker",
                    "flight_id": flight_id,
                    "airline": random.choice(["ITA", "Ryanair", "easyJet", "WizzAir"]),
                    "service_date": sim_date.isoformat(),
                    "origin_iata": random.choice(list(self.airports["airport_code"].dropna().unique())),
                    "destination_iata": iata,
                    "destination_city_id": city_id,
                    "scheduled_departure": sched_dep.strftime("%Y-%m-%dT%H:%M:%SZ"),
                    "actual_departure": None if status == "cancelled" else (sched_dep + timedelta(minutes=max(0, delay))).strftime("%Y-%m-%dT%H:%M:%SZ"),
                    "scheduled_arrival": sched_arr.strftime("%Y-%m-%dT%H:%M:%SZ"),
                    "actual_arrival": None if status == "cancelled" else (sched_arr + timedelta(minutes=max(0, delay))).strftime("%Y-%m-%dT%H:%M:%SZ"),
                    "status": status,
                    "delay_min": None if delay is None else int(delay),
                    "load_factor": round(load, 2),
                    "aircraft_type": random.choice(["A320", "A321", "B737", "A319"]),
                    "seats": seats,
                    "weather_factor": round(weather_factor, 3),
                    "airport_congestion": round(congestion, 3)
                }
                self.emit(self.topics["flights"], f"{iata}|{flight_id}", payload)
                self.cnt_flights += 1

    def gen_bookings_for_date(self, sim_date):
        for cid, meta in self.city_meta.items():
            s = seasonality(meta["row"], sim_date)
            hotels = meta["hotels"]
            if len(hotels) == 0:
                continue
            base = max(0.5, meta["population"] / 100000.0 * 10.0 * s)
            # Ø¨Ø±Ø§ÛŒ Ø¯Ù…Ùˆ: Ø­Ø¯Ø§Ù‚Ù„ 1 Ø±Ø²Ø±Ùˆ
            nb = max(1, int(np.random.poisson(base)))
            for _ in range(nb):
                hotel = random.choice(hotels)
                lead = sample_lead_time(1.0)
                checkin = sim_date + timedelta(days=lead)
                nights = max(1, int(random.choice([1, 1, 2, 2, 3, 4])))
                adr = max(30.0, float(hotel.get("stars_num") or 3.0) * 30 + random.gauss(0, 20) + 5 * s)
                booking = {
                    "schema_version": "v1",
                    "event_type": "booking_created",
                    "event_ts": now_iso(),
                    "ingest_ts": now_iso(),
                    "trace_id": make_trace(),
                    "producer": "faker",
                    "booking_id": f"BKG-{uuid.uuid4().hex[:8]}",
                    "hotel_id": hotel["hotel_id"],
                    "city_id": cid,
                    "city_name": hotel.get("city_name"),
                    "checkin_date": checkin.isoformat(),
                    "checkout_date": (checkin + timedelta(days=nights)).isoformat(),
                    "nights": nights,
                    "guests": random.choice([1, 2, 2, 3]),
                    "rooms": 1,
                    "channel": random.choices(["direct", "ota", "corporate"], weights=[0.4, 0.5, 0.1])[0],
                    "lead_time_days": lead,
                    "adr_proxy": round(adr, 2),
                    "currency": "EUR",
                    "is_refundable": random.random() < 0.7,
                    "status": "active",
                    "cancel_ts": None,
                    "flight_anchor": {
                        "predicted_inbound": int(meta["population"] / 1000.0 * s),
                    }
                }
                if random.random() < 0.005:
                    booking["status"] = "cancelled"
                    booking["cancel_ts"] = now_iso()
                self.emit(self.topics["bookings"], f"{cid}|{booking['checkin_date']}", booking)
                self.cnt_bookings += 1

# --------- Main runner ----------
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--base", default="/home/tahmast/Projects/Tourism")
    ap.add_argument("--bootstrap-servers", default="localhost:9092")
    ap.add_argument("--mode", choices=["realtime", "timewarp"], default="timewarp")
    ap.add_argument("--rate", type=int, default=1000, help="target msgs/sec when accelerating")
    ap.add_argument("--days", type=int, default=365, help="how many simulated days")
    ap.add_argument("--timewarp", type=int, default=1000, help="speedup factor for timewarp (1 = real time)")

    # Light-mode sampling to reduce CPU/RAM load on 8GB
    ap.add_argument("--sample-cities", type=int, default=0, help="if >0, keep only N cities")
    ap.add_argument("--sample-airports", type=int, default=0, help="if >0, keep only N airports")
    ap.add_argument("--sample-hotels", type=int, default=0, help="if >0, keep only N hotels")

    # Debug switch (1=on, 0=off)
    ap.add_argument("--debug", type=int, default=1, help="enable librdkafka debug logs (1 on / 0 off)")

    args = ap.parse_args()

    hotels, airports, cities, iata_map = load_inputs(args.base)

    # ----- sampling & alignment -----
    if args.sample_cities and args.sample_cities > 0:
        cities = cities.head(args.sample_cities).copy()

    # align hotels with selected cities
    hotels = hotels[hotels["city_id"].isin(cities["city_id"])].copy()
    if args.sample_hotels and args.sample_hotels > 0:
        hotels = hotels.head(args.sample_hotels).copy()

    if args.sample_airports and args.sample_airports > 0:
        airports = airports.head(args.sample_airports).copy()

    # fallback if filtering made hotels empty
    if len(hotels) == 0:
        hotels_full = pd.read_csv(Path(args.base)/"data/curated/hotels_clean.csv", dtype=str)
        hotels = hotels_full[hotels_full["city_id"].isin(cities["city_id"])].head(300).copy()

    print("Loaded shapes (post-alignment):", len(hotels), len(airports), len(cities))

    conf = {
        "bootstrap.servers": args.bootstrap_servers,
        "linger.ms": 100,                 # batching to reduce CPU
        "compression.type": "lz4",
        "acks": "1",                      # lighter than 'all' for single-node
        "enable.idempotence": False,
        "statistics.interval.ms": 0,
    }
    if args.debug:
        conf["debug"] = "broker,topic,msg"

    p = Producer(conf)
    topics = {"flights": "flight.events.v1", "bookings": "booking.events.v1", "weather": "weather.events.v1"}
    sim = Simulator(hotels, airports, cities, iata_map, p, topics)

    if args.mode == "realtime":
        print("Starting realtime loop (ctrl-c to stop)...")
        while True:
            d = date.today()
            sim.gen_weather_for_date(d)
            sim.gen_flights_for_date(d)
            sim.gen_bookings_for_date(d)
            print(f"[{d}] produced: weather={sim.cnt_weather} flights={sim.cnt_flights} bookings={sim.cnt_bookings}")
            time.sleep(max(0.02, 1.0 / max(1, args.rate)))
    else:
        days = args.days
        print(f"Simulating {days} days with timewarp factor {args.timewarp}, target rate {args.rate} msgs/sec...")
        for dd in range(days):
            sim_date = date.today() + timedelta(days=dd)
            sim.gen_weather_for_date(sim_date)
            sim.gen_flights_for_date(sim_date)
            sim.gen_bookings_for_date(sim_date)
            print(f"[{sim_date}] produced: weather={sim.cnt_weather} flights={sim.cnt_flights} bookings={sim.cnt_bookings}")
            # flush lightly so callbacks fire
            p.flush(0)
            # tiny pacing to avoid CPU spikes
            time.sleep(0.001)

    p.flush(10)
    print("Done.")

if __name__ == "__main__":
    main()

```

Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø«Ø§Ù„:

```
cd ~/Projects/Tourism
python producers/orchestrator_producers.py \
  --mode timewarp --days 3 --timewarp 500 --rate 800 \
  --bootstrap-servers localhost:9092 \
  --base /home/tahmast/Projects/Tourism \
  --sample-cities 15 --sample-airports 5 --sample-hotels 300 \
  --debug 1
```

Ø®Ø±ÙˆØ¬ÛŒ Ù†Ù…ÙˆÙ†Ù‡:

```
[2025-10-19] produced: weather=495 flights=381 bookings=119
```

Ø§ÛŒÙ†Ùˆ Ù‡Ù†ÙˆØ² ØªØ³Øª Ù†Ú©Ø±Ø¯Ù…

```
#!/usr/bin/env python3
# producers/orchestrator_producers.py
"""
Unified generator for flights, bookings and weather.

Examples:
  # timewarp: simulate N days from a given start date (batch per day)
  python producers/orchestrator_producers.py --mode timewarp --sim-start 2023-01-01 --days 30 --timewarp 500

  # realtime: simulated time moves with wall-clock (1x)
  python producers/orchestrator_producers.py --mode realtime --sim-start 2023-01-01 --timewarp 1

  # realtime: "every 10 real minutes == ~1 simulated month"
  python producers/orchestrator_producers.py --mode realtime --sim-start 2023-01-01 --month-interval 10 --month-days 30
"""

import argparse, random, uuid, json, math, time
from datetime import datetime, timedelta, date, timezone
from pathlib import Path
import pandas as pd
import numpy as np
from confluent_kafka import Producer

# ========= Helpers =========
def to_iso(dt: datetime) -> str:
    """UTC-aware datetime -> ISO8601 Z"""
    if dt.tzinfo is None:
        dt = dt.replace(tzinfo=timezone.utc)
    return dt.astimezone(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")

def make_trace():
    return uuid.uuid4().hex

def sample_lead_time(city_type_factor: float) -> int:
    """mixed business (exp mean=5) + leisure (normal mean=30)"""
    if random.random() < 0.35 * city_type_factor:
        return max(0, int(random.expovariate(1/5)))
    else:
        return max(1, int(random.gauss(30, 20)))

def seasonality(city_row: dict, sim_date: date) -> float:
    m = sim_date.month
    base = 1.0
    # Ø§Ú¯Ø± Ø¯Ø± Ø¯ÛŒØªØ§Ø³Øª peak_months Ø¨Ù‡â€ŒØµÙˆØ±Øª list Ø¨Ø§Ø´Ø¯ØŒ Ø§Ø«Ø± Ø¨Ø¯Ù‡
    if "peak_months" in city_row and isinstance(city_row["peak_months"], list):
        if m in city_row["peak_months"]:
            base *= 1.4
    # Ø¢Ø®Ø± Ù‡ÙØªÙ‡
    if sim_date.weekday() >= 5:
        base *= 1.15
    # Ù…Ù‚ÛŒØ§Ø³ Ø¬Ù…Ø¹ÛŒØª
    pop = float(city_row.get("population", 10000) or 10000)
    base *= (1 + math.log1p(pop)/12.0)
    return base

# ========= Load data =========
def load_inputs(base):
    base = Path(base)
    hotels = pd.read_csv(base/"data/curated/hotels_clean.csv", dtype=str)
    airports = pd.read_csv(base/"data/curated/airports_it.csv", dtype=str)
    cities = pd.read_csv(base/"data/curated/cities_it_enriched_cleaned.csv", dtype=str)

    if "population" not in cities.columns:
        cities["population"] = 10000
    cities["population"] = pd.to_numeric(cities["population"], errors="coerce").fillna(10000)

    if "airport_code" in airports.columns and "city_name" in airports.columns:
        airports["iata"] = airports["airport_code"].astype(str)
        iata_to_city = airports.set_index("airport_code")["city_name"].to_dict()
    else:
        iata_to_city = {}

    return hotels, airports, cities, iata_to_city

# ========= Delivery report =========
def _dr_cb(err, msg):
    if err:
        print("Delivery failed:", err)

# ========= Core =========
class Simulator:
    def __init__(self, hotels, airports, cities, iata_map, producer, topics):
        self.hotels = hotels
        self.airports = airports
        self.cities = cities
        self.iata_map = iata_map
        self.producer = producer
        self.topics = topics

        # per-day counters
        self.cnt_weather = 0
        self.cnt_flights = 0
        self.cnt_bookings = 0

        # simulated clock (UTC, set from runner)
        self.sim_now = datetime.now(timezone.utc)

        # Precompute city meta
        self.city_meta = {}
        for _, r in cities.iterrows():
            cid = str(r["city_id"])
            pop = float(r.get("population", 10000) or 10000)
            self.city_meta[cid] = {
                "population": pop,
                "row": r.to_dict(),
                "hotels": hotels[hotels["city_id"] == cid].to_dict("records")
            }

    def set_clock(self, sim_now: datetime):
        if sim_now.tzinfo is None:
            sim_now = sim_now.replace(tzinfo=timezone.utc)
        self.sim_now = sim_now

    def emit(self, topic, key, value):
        payload = json.dumps(value).encode("utf-8")
        keyb = str(key).encode("utf-8")
        try:
            self.producer.produce(topic, payload, key=keyb, on_delivery=_dr_cb)
            self.producer.poll(0)  # trigger callbacks
        except BufferError as e:
            print("Local queue is full, backing off...", e)
            self.producer.poll(0.5)
            self.producer.produce(topic, payload, key=keyb, on_delivery=_dr_cb)

    def gen_weather_for_date(self, sim_date: date):
        for cid, meta in self.city_meta.items():
            row = meta["row"]
            month = sim_date.month
            t_base = 5 + (month/12.0)*20 + random.gauss(0, 3)
            precip = max(0, random.gauss(2 + (12-month)/6.0, 5))
            condition = "clear"
            if precip > 10:
                condition = random.choice(["rain", "storm"])
            elif precip > 2:
                condition = "rain"

            # peak_months Ø§Ú¯Ø± Ø¨Ù‡â€ŒØµÙˆØ±Øª Ø±Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
            is_peak = False
            if "peak_months" in row and isinstance(row["peak_months"], str):
                try:
                    peaks = [int(x) for x in row["peak_months"].strip("[]").split(",") if x]
                    is_peak = sim_date.month in peaks
                except Exception:
                    is_peak = False

            event_ts = datetime(sim_date.year, sim_date.month, sim_date.day, 0, 0, tzinfo=timezone.utc)
            payload = {
                "schema_version": "v1",
                "event_type": "daily_weather",
                "event_ts": to_iso(event_ts),
                "ingest_ts": to_iso(self.sim_now),
                "trace_id": make_trace(),
                "producer": "faker",
                "city_id": cid,
                "date": sim_date.isoformat(),
                "t_min": round(t_base - random.uniform(2, 6), 1),
                "t_max": round(t_base + random.uniform(2, 6), 1),
                "precip_mm": round(precip, 1),
                "wind_kph": round(max(0, random.gauss(12, 8)), 1),
                "humidity": round(min(1.0, max(0, random.gauss(0.6, 0.15))), 2),
                "condition": condition,
                "is_peak_season": is_peak,
                "holiday_flag": False
            }
            self.emit(self.topics["weather"], f"{cid}|{sim_date.isoformat()}", payload)
            self.cnt_weather += 1

    def gen_flights_for_date(self, sim_date: date):
        for _, ap in self.airports.iterrows():
            iata = ap.get("airport_code")
            city_name = ap.get("city_name")
            if city_name:
                m = self.cities[
                    self.cities["city_name"].fillna("").str.lower().str.contains(str(city_name).lower(), regex=False)
                ]
                if len(m) > 0:
                    city_row = m.iloc[0].to_dict()
                    city_id = str(city_row["city_id"])
                else:
                    city_id = random.choice(list(self.city_meta.keys()))
                    city_row = self.city_meta[city_id]["row"]
            else:
                city_id = random.choice(list(self.city_meta.keys()))
                city_row = self.city_meta[city_id]["row"]

            s = seasonality(city_row, sim_date)
            pop = float(city_row.get("population", 10000))
            expected_arrivals = max(1, int((pop / 2000.0) * s))

            for _ in range(expected_arrivals):
                flight_id = f"FA{random.randint(100, 9999)}"
                seats = random.choice([100, 150, 180, 220])
                load = min(1.0, max(0.3, random.gauss(0.7, 0.12)))
                weather_factor = random.random() * 0.15
                congestion = random.random() * 0.15
                delay = int(random.gauss(5, 10) + (weather_factor + congestion) * 60)
                status = "arrived"
                if random.random() < 0.01 + weather_factor * 0.5:
                    status = "cancelled"
                    delay = None

                sched_dep = datetime(sim_date.year, sim_date.month, sim_date.day,
                                     random.randint(0, 23), random.choice([0, 15, 30, 45]),
                                     tzinfo=timezone.utc)
                sched_arr = sched_dep + timedelta(minutes=random.randint(40, 180))
                event_ts = (sched_arr + timedelta(minutes=(delay or 0)))

                payload = {
                    "schema_version": "v1",
                    "event_type": "flight_arrival",
                    "event_ts": to_iso(event_ts),
                    "ingest_ts": to_iso(self.sim_now),
                    "trace_id": make_trace(),
                    "producer": "faker",
                    "flight_id": flight_id,
                    "airline": random.choice(["ITA", "Ryanair", "easyJet", "WizzAir"]),
                    "service_date": sim_date.isoformat(),
                    "origin_iata": random.choice(list(self.airports["airport_code"].dropna().unique())),
                    "destination_iata": iata,
                    "destination_city_id": city_id,
                    "scheduled_departure": to_iso(sched_dep),
                    "actual_departure": None if status == "cancelled" else to_iso(sched_dep + timedelta(minutes=max(0, delay))),
                    "scheduled_arrival": to_iso(sched_arr),
                    "actual_arrival": None if status == "cancelled" else to_iso(sched_arr + timedelta(minutes=max(0, delay))),
                    "status": status,
                    "delay_min": None if delay is None else int(delay),
                    "load_factor": round(load, 2),
                    "aircraft_type": random.choice(["A320", "A321", "B737", "A319"]),
                    "seats": seats,
                    "weather_factor": round(weather_factor, 3),
                    "airport_congestion": round(congestion, 3)
                }
                self.emit(self.topics["flights"], f"{iata}|{flight_id}", payload)
                self.cnt_flights += 1

    def gen_bookings_for_date(self, sim_date: date):
        for cid, meta in self.city_meta.items():
            s = seasonality(meta["row"], sim_date)
            hotels = meta["hotels"]
            if len(hotels) == 0:
                continue
            base = max(0.5, meta["population"] / 100000.0 * 10.0 * s)
            nb = max(1, int(np.random.poisson(base)))  # Ø­Ø¯Ø§Ù‚Ù„ 1 Ø±Ø²Ø±Ùˆ Ø¨Ø±Ø§ÛŒ Ø¯Ù…ÙˆÛŒ ÙˆØ§Ø¶Ø­
            for _ in range(nb):
                hotel = random.choice(hotels)
                lead = sample_lead_time(1.0)
                checkin = sim_date + timedelta(days=lead)
                nights = max(1, int(random.choice([1, 1, 2, 2, 3, 4])))
                adr = max(30.0, float(hotel.get("stars_num") or 3.0) * 30 + random.gauss(0, 20) + 5 * s)
                payload = {
                    "schema_version": "v1",
                    "event_type": "booking_created",
                    "event_ts": to_iso(self.sim_now),   # Ø±Ø®Ø¯Ø§Ø¯ Ø±Ø²Ø±Ùˆ Ø¯Ø± "Ø­Ø§Ù„Ù Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ"
                    "ingest_ts": to_iso(self.sim_now),  # Ø²Ù…Ø§Ù† Ø¯Ø±Ø¬ Ù†ÛŒØ² Ù‡Ù…Ø§Ù†
                    "trace_id": make_trace(),
                    "producer": "faker",
                    "booking_id": f"BKG-{uuid.uuid4().hex[:8]}",
                    "hotel_id": hotel["hotel_id"],
                    "city_id": cid,
                    "city_name": hotel.get("city_name"),
                    "checkin_date": checkin.isoformat(),
                    "checkout_date": (checkin + timedelta(days=nights)).isoformat(),
                    "nights": nights,
                    "guests": random.choice([1, 2, 2, 3]),
                    "rooms": 1,
                    "channel": random.choices(["direct", "ota", "corporate"], weights=[0.4, 0.5, 0.1])[0],
                    "lead_time_days": lead,
                    "adr_proxy": round(adr, 2),
                    "currency": "EUR",
                    "is_refundable": random.random() < 0.7,
                    "status": "active",
                    "cancel_ts": None,
                    "flight_anchor": {
                        "predicted_inbound": int(meta["population"] / 1000.0 * s),
                    }
                }
                if random.random() < 0.005:
                    payload["status"] = "cancelled"
                    payload["cancel_ts"] = to_iso(self.sim_now)
                self.emit(self.topics["bookings"], f"{cid}|{payload['checkin_date']}", payload)
                self.cnt_bookings += 1

# ========= Runner =========
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--base", default="/home/tahmast/Projects/Tourism")
    ap.add_argument("--bootstrap-servers", default="localhost:9092")
    ap.add_argument("--mode", choices=["realtime", "timewarp"], default="timewarp")
    ap.add_argument("--rate", type=int, default=1000, help="target msgs/sec when accelerating")
    ap.add_argument("--days", type=int, default=365, help="how many simulated days")
    ap.add_argument("--timewarp", type=float, default=1000.0, help="speedup factor (used in both modes)")
    ap.add_argument("--sim-start", type=str, default="2023-01-01", help="simulation start date (YYYY-MM-DD)")

    # NEW: map "real minutes" -> "one simulated month"
    ap.add_argument("--month-interval", type=float, default=None,
                    help="Real minutes per one simulated month (overrides --timewarp if set). Example: 10 => every 10 real minutes advance ~1 simulated month.")
    ap.add_argument("--month-days", type=float, default=30.0,
                    help="Days considered as one simulated month when computing timewarp (default 30.0; use 30.44 for average).")

    # Light-mode sampling
    ap.add_argument("--sample-cities", type=int, default=0)
    ap.add_argument("--sample-airports", type=int, default=0)
    ap.add_argument("--sample-hotels", type=int, default=0)

    ap.add_argument("--debug", type=int, default=1)
    args = ap.parse_args()

    # ---- compute timewarp from month-interval (if provided) ----
    if args.month_interval and args.month_interval > 0:
        args.timewarp = (args.month_days * 24.0 * 60.0) / args.month_interval
        print(f"[cfg] month-interval={args.month_interval:.2f} min, month-days={args.month_days:.2f} -> timewarp={args.timewarp:.2f}x")

    hotels, airports, cities, iata_map = load_inputs(args.base)

    # sampling & alignment
    if args.sample_cities and args.sample_cities > 0:
        cities = cities.head(args.sample_cities).copy()
    hotels = hotels[hotels["city_id"].isin(cities["city_id"])].copy()
    if args.sample_hotels and args.sample_hotels > 0:
        hotels = hotels.head(args.sample_hotels).copy()
    if args.sample_airports and args.sample_airports > 0:
        airports = airports.head(args.sample_airports).copy()
    if len(hotels) == 0:
        hotels_full = pd.read_csv(Path(args.base)/"data/curated/hotels_clean.csv", dtype=str)
        hotels = hotels_full[hotels_full["city_id"].isin(cities["city_id"])].head(300).copy()

    print("Loaded shapes (post-alignment):", len(hotels), len(airports), len(cities))

    conf = {
        "bootstrap.servers": args.bootstrap_servers,
        "linger.ms": 100,
        "compression.type": "lz4",
        "acks": "1",
        "enable.idempotence": False,
        "statistics.interval.ms": 0,
    }
    if args.debug:
        conf["debug"] = "broker,topic,msg"

    p = Producer(conf)
    topics = {"flights": "flight.events.v1", "bookings": "booking.events.v1", "weather": "weather.events.v1"}
    sim = Simulator(hotels, airports, cities, iata_map, p, topics)

    # Simulation start (date & datetime)
    sim_start_date = date.fromisoformat(args.sim_start)
    sim_start_dt = datetime(sim_start_date.year, sim_start_date.month, sim_start_date.day, 0, 0, tzinfo=timezone.utc)

    if args.mode == "realtime":
        print("Starting realtime loop (ctrl-c to stop)...")
        wall_start = datetime.now(timezone.utc)
        last_emitted_date = None

        while True:
            # simulated now = sim_start + elapsed_real * timewarp
            elapsed = datetime.now(timezone.utc) - wall_start
            sim_now = sim_start_dt + elapsed * max(1.0, float(args.timewarp))
            sim.set_clock(sim_now)
            sim_date = sim_now.date()

            # emit exactly once per simulated day
            if last_emitted_date != sim_date:
                sim.cnt_weather = sim.cnt_flights = sim.cnt_bookings = 0
                sim.gen_weather_for_date(sim_date)
                sim.gen_flights_for_date(sim_date)
                sim.gen_bookings_for_date(sim_date)
                print(f"[{sim_date}] produced: weather={sim.cnt_weather} flights={sim.cnt_flights} bookings={sim.cnt_bookings}")
                p.flush(0)
                last_emitted_date = sim_date

            time.sleep(max(0.02, 1.0 / max(1, args.rate)))

    else:
        days = args.days
        print(f"Simulating {days} days from {sim_start_date} with timewarp={args.timewarp}, rate={args.rate} msgs/sec...")
        for dd in range(days):
            sim_date = sim_start_date + timedelta(days=dd)
            # Ø¨Ø±Ø§ÛŒ ingest_ts ÛŒÚ© Ø²Ù…Ø§Ù† Ù…ÛŒØ§Ù†Ù‡ Ø±ÙˆØ² Ø³Øª Ú©Ù†ÛŒÙ…
            sim.set_clock(datetime(sim_date.year, sim_date.month, sim_date.day, 12, 0, tzinfo=timezone.utc))
            sim.cnt_weather = sim.cnt_flights = sim.cnt_bookings = 0

            sim.gen_weather_for_date(sim_date)
            sim.gen_flights_for_date(sim_date)
            sim.gen_bookings_for_date(sim_date)

            print(f"[{sim_date}] produced: weather={sim.cnt_weather} flights={sim.cnt_flights} bookings={sim.cnt_bookings}")
            p.flush(0)
            time.sleep(0.001)

    p.flush(10)
    print("Done.")

if __name__ == "__main__":
    main()

```

## Ø§Ø¬Ø±Ø§ÛŒ Ø¢Ù…Ø§Ø¯Ù‡ (Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§)

### 1) Ù‡Ø± **Û±Û° Ø¯Ù‚ÛŒÙ‚Ù‡ ÙˆØ§Ù‚Ø¹ÛŒ = ~Û± Ù…Ø§Ù‡ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ**

(ÛŒØ¹Ù†ÛŒ ØªÙ‚Ø±ÛŒØ¨Ø§Ù‹ Ù‡Ø± **Û²Û° Ø«Ø§Ù†ÛŒÙ‡ ÙˆØ§Ù‚Ø¹ÛŒ** ÛŒÚ© Â«Ø±ÙˆØ²Â» ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯)

```
python producers/orchestrator_producers.py \
  --mode realtime \
  --sim-start 2023-01-01 \
  --month-interval 10 \
  --month-days 30 \
  --rate 1 \
  --bootstrap-servers localhost:9092 \
  --base /home/tahmast/Projects/Tourism \
  --sample-cities 15 --sample-airports 5 --sample-hotels 300 \
  --debug 0
```

### 2) Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø±ÛŒØ¹ Û¶Û° Ø±ÙˆØ² Ø§Ø² Ø§Ø¨ØªØ¯Ø§ÛŒ Û²Û°Û²Û³ (batch)

```
python producers/orchestrator_producers.py \
  --mode timewarp \
  --sim-start 2023-01-01 \
  --days 60 \
  --timewarp 1000 \
  --bootstrap-servers localhost:9092 \
  --base /home/tahmast/Projects/Tourism \
  --sample-cities 15 --sample-airports 5 --sample-hotels 300 \
  --debug 0
```

Ø§Ú¯Ø± Ø®ÙˆØ§Ø³ØªÛŒ Ø¨Ø¹Ø¯Ø§Ù‹ **granularity ØªÙˆÙ„ÛŒØ¯** Ø±Ùˆ Ù‡Ù… Ù¾Ø§Ø±Ø§Ù…ØªØ±ÛŒÚ© Ú©Ù†ÛŒÙ… (Ù…Ø«Ù„Ø§Ù‹ Ø¨Ù‡â€ŒØ¬Ø§ÛŒ Ø±ÙˆØ²ØŒ Â«Ù‡ÙØªÙ‡/Ù…Ø§Ù‡/Ø³Ø§Ø¹ØªÂ» ØªÙˆÙ„ÛŒØ¯ Ú©Ù†Ù‡)ØŒ Ù‡Ù… Ù…ÛŒâ€ŒØªÙˆÙ†Ù… Ú¯Ø²ÛŒÙ†Ù‡Ù” `--emit-granularity` Ø±Ùˆ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†Ù… ØªØ§ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ seasonal (Ø±ÙˆØ²/Ù‡ÙØªÙ‡/Ù…Ø§Ù‡/ÙØµÙ„) Ø±Ø§Ø­Øªâ€ŒØªØ± ØªØ³Øª Ø¨Ø´Ù†.



## Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§

### ğŸ”¹ Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø§Ù…Ù„ Ø¨Ø§ Ù‡Ù…Ù‡â€ŒÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§

```
python producers/orchestrator_producers.py \
  --mode realtime \
  --sim-start 2023-01-01 \
  --month-interval 10 \
  --sample-cities 0 --sample-airports 0 --sample-hotels 0 \
  --base /home/tahmast/Projects/Tourism \
  --bootstrap-servers localhost:9092
  

```

âœ… Ø§Ø² **ØªÙ…Ø§Ù…** Ø´Ù‡Ø±Ù‡Ø§ØŒ ÙØ±ÙˆØ¯Ú¯Ø§Ù‡â€ŒÙ‡Ø§ Ùˆ Ù‡ØªÙ„â€ŒÙ‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.



## 6. Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (Consumers)

Ù†Ù…Ø§ÛŒØ´ Û²Û° Ù¾ÛŒØ§Ù… Ø§ÙˆÙ„ Ø§Ø² ØªØ§Ù¾ÛŒÚ© Ù‡ÙˆØ§Ø´Ù†Ø§Ø³ÛŒ:

```
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 \
  --topic weather.events.v1 --from-beginning --max-messages 20
```

Ù†Ù…Ø§ÛŒØ´ Ø±Ø²Ø±ÙˆÙ‡Ø§:

```
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 \
  --topic booking.events.v1 --from-beginning --max-messages 10
```

Ø§Ú¯Ø± Ù¾ÛŒØ§Ù… Ù†Ø¯ÛŒØ¯ÛŒØŒ Ø¨Ø§ Ú¯Ø±ÙˆÙ‡ Ø¬Ø¯ÛŒØ¯ ØªØ³Øª Ú©Ù†:

```
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 \
  --topic booking.events.v1 --group demo.book.view \
  --from-beginning --max-messages 20
  
  bin/kafka-console-consumer --bootstrap-server localhost:9092 \
  --topic booking.events.v1 --from-beginning

```

##  7. Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† ÛŒØ§ Ø±ÛŒØ³Øª ØªØ§Ù¾ÛŒÚ©â€ŒÙ‡Ø§

### ğŸ”¹ Ø­Ø°Ù Ú©Ø§Ù…Ù„ Ùˆ Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ

```
for t in booking.events.v1 flight.events.v1 weather.events.v1; do
  bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic "$t"
done

sleep 3

for t in booking.events.v1 flight.events.v1 weather.events.v1; do
  bin/kafka-topics.sh --bootstrap-server localhost:9092 \
    --create --topic "$t" --partitions 1 --replication-factor 1
done
```

### ğŸ”¹ ÛŒØ§ ÙÙ‚Ø· Ø®Ø§Ù„ÛŒ Ú©Ø±Ø¯Ù† Ù…Ø­ØªÙˆØ§ Ø¨Ø¯ÙˆÙ† Ø­Ø°Ù

```
for t in booking.events.v1 flight.events.v1 weather.events.v1; do
  bin/kafka-configs.sh --bootstrap-server localhost:9092 \
    --alter --entity-type topics --entity-name "$t" \
    --add-config retention.ms=1000
done
sleep 3
for t in booking.events.v1 flight.events.v1 weather.events.v1; do
  bin/kafka-configs.sh --bootstrap-server localhost:9092 \
    --alter --entity-type topics --entity-name "$t" \
    --add-config retention.ms=604800000
done
```

##  8. Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ùˆ Ø¯ÛŒØ¨Ø§Ú¯

Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø®Ø±ÛŒÙ† offset (Ø¨Ø§ÛŒØ¯ > 0 Ø¨Ø§Ø´Ø¯):

```
bin/kafka-run-class kafka.tools.GetOffsetShell \
  --broker-list localhost:9092 --topic booking.events.v1
```

Reset Ú©Ø±Ø¯Ù† consumer offsets:

```
bin/kafka-consumer-groups.sh \
  --bootstrap-server localhost:9092 \
  --group demo.book.view \
  --topic booking.events.v1 \
  --reset-offsets --to-earliest --execute
```



## Ø¨Ø±ÛŒÙ… Ø³Ø±Ø§Øº Ø§Ø³Ù¾Ø§Ø±Ú©



```
pip install pyspark

```

```
# Pushgateway (Ù¾ÙˆØ±Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 9091)
wget https://github.com/prometheus/pushgateway/releases/download/v1.8.0/pushgateway-1.8.0.linux-amd64.tar.gz
tar xf pushgateway-*.tar.gz
./pushgateway-*/pushgateway --web.listen-address=":9091"

# Prometheus (Ù¾ÙˆØ±Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 9090)
wget https://github.com/prometheus/prometheus/releases/download/v2.55.1/prometheus-2.55.1.linux-amd64.tar.gz
tar xf prometheus-*.tar.gz
cd prometheus-*/ 
cat > prometheus.yml <<'YAML'
global:
  scrape_interval: 5s
scrape_configs:
  - job_name: 'pushgateway'
    honor_labels: true
    static_configs:
      - targets: ['localhost:9091']
YAML
./prometheus --config.file=prometheus.yml --web.listen-address=":9090"

# Grafana (Ù¾ÙˆØ±Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 3000)
# Ø§ÙˆØ¨ÙˆÙ†ØªÙˆ:
sudo apt-get install -y adduser libfontconfig1
wget https://dl.grafana.com/oss/release/grafana_11.1.0_amd64.deb
sudo dpkg -i grafana_11.1.0_amd64.deb
sudo systemctl start grafana-server
# ÙˆØ±ÙˆØ¯ ÙˆØ¨: http://localhost:3000  (admin / admin)

```

Ø¯Ø§Ø®Ù„ Grafana ÛŒÚ© **Prometheus data source** Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†: URL = `http://localhost:9090`.

```
export SPARK_HOME=$(python - <<'PY'
import pyspark, pathlib
print(pathlib.Path(pyspark.__file__).parent)
PY)
export PATH="$SPARK_HOME/bin:$PATH"

pip install requests
# Ø¯Ø§Ø®Ù„ Ù‡Ù…Ø§Ù† Ø´ÙÙ„Ù venv
which python
# Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø§ÛŒØ¯ Ú†ÛŒØ²ÛŒ Ø´Ø¨ÛŒÙ‡ Ø§ÛŒÙ† Ø¨Ø§Ø´Ù‡:
# /home/tahmast/myenvironments/Tourism/bin/python

export PYSPARK_PYTHON=/home/tahmast/myenvironments/Tourism/bin/python
export PYSPARK_DRIVER_PYTHON=/home/tahmast/myenvironments/Tourism/bin/python
```

```
$SPARK_HOME/bin/spark-submit \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.13:4.0.1 \
  --conf spark.sql.shuffle.partitions=4 \
  spark/kafka_to_metrics.py

```

```
export SPARK_HOME=~/tools/spark-4.0.1-bin-hadoop3
export PATH="$SPARK_HOME/bin:$PATH"

rm -rf ~/.ivy2*/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.1.jar
rm -rf ~/.ivy2*/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.1.jar

$SPARK_HOME/bin/spark-submit \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.13:4.0.1 \
  spark/just_console_weather.py
  
```

cd ~/tools/pushgateway-*/     # Ù…Ø³ÛŒØ± Ù¾ÙˆØ´Ù‡Ù” pushgateway Ø®ÙˆØ¯Øª
./pushgateway --web.listen-address=":9091" &





cd ~/tools/prometheus-2.55.1.linux-amd64
./prometheus \
  --config.file=./prometheus.yml \
  --storage.tsdb.path=./data \
  --web.listen-address=":9090" &



server kafka. producer kafka. spark prometheus pushgateway must be up



### ğŸ¯ Ø¹Ù†ÙˆØ§Ù† Ù¾Ø±ÙˆÚ˜Ù‡

**Real-Time Tourism Analytics Platform (Kafka + Spark + Prometheus + Grafana)**

------

### ğŸ§© Ú†Ø§Ù„Ø´

Ø¯Ø± ØµÙ†Ø¹Øª Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒØŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø®ØªÙ„Ù Ùˆ Ø¨Ø§ Ø³Ø±Ø¹Øª Ø¨Ø§Ù„Ø§ ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ â€” Ù¾Ø±ÙˆØ§Ø²Ù‡Ø§ØŒ Ø±Ø²Ø±Ùˆ Ù‡ØªÙ„â€ŒÙ‡Ø§ØŒ Ùˆ Ø´Ø±Ø§ÛŒØ· Ø¢Ø¨â€ŒÙˆÙ‡ÙˆØ§. Ø§Ù…Ø§ Ø§ØºÙ„Ø¨ Ø§ÛŒÙ† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¬Ø¯Ø§ Ø§Ø² Ù‡Ù… Ù‡Ø³ØªÙ†Ø¯ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø¢Ù†â€ŒÙ‡Ø§ Ø¨Ø§ ØªØ£Ø®ÛŒØ± Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ù…Ø¯ÛŒØ±Ø§Ù† Ø´Ù‡Ø±ÛŒØŒ Ø´Ø±Ú©Øªâ€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ§Ù¾ÛŒÙ…Ø§ÛŒÛŒ Ùˆ Ù‡ØªÙ„â€ŒØ¯Ø§Ø±Ø§Ù† Ù†ÛŒØ§Ø² Ø¯Ø§Ø±Ù†Ø¯ **Ø¯Ø± Ù„Ø­Ø¸Ù‡** Ø¨Ø¯Ø§Ù†Ù†Ø¯:

- Ú©Ø¯Ø§Ù… Ø´Ù‡Ø±Ù‡Ø§ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ú¯Ø±Ø¯Ø´Ú¯Ø± Ø±Ø§ Ø¯Ø§Ø±Ù†Ø¯ØŸ
- Ù†Ø±Ø® Ù„ØºÙˆ Ù¾Ø±ÙˆØ§Ø²Ù‡Ø§ Ùˆ ØªØ£Ø®ÛŒØ±Ù‡Ø§ Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ
- Ú†Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø§Ø² Ø³Ø§Ù„ Ø³ÙØ± Ø§Ø±Ø²Ø§Ù†â€ŒØªØ± Ùˆ Ú©Ù…â€ŒØªØ±Ø§ÙÛŒÚ©â€ŒØªØ± Ø§Ø³ØªØŸ
   Ø¯Ø± Ù†ØªÛŒØ¬Ù‡ØŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ ÛŒÚ© Ø³ÛŒØ³ØªÙ… real-time Ø¯Ø§Ø´ØªÛŒÙ… Ú©Ù‡ Ø§ÛŒÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø±Ø§ **Ø¨Ù‡â€ŒØµÙˆØ±Øª Ø²Ù†Ø¯Ù‡ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒØŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ù…ØµÙˆØ±Ø³Ø§Ø²ÛŒ Ú©Ù†Ø¯**.

------

### âš™ï¸ Ø±Ø§Ù‡â€ŒØ­Ù„

Ø¨Ø±Ø§ÛŒ Ø­Ù„ Ø§ÛŒÙ† Ù…Ø³Ø¦Ù„Ù‡ØŒ ÛŒÚ© Ù¾Ø§ÛŒÙ¾â€ŒÙ„Ø§ÛŒÙ† end-to-end Ø·Ø±Ø§Ø­ÛŒ Ùˆ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯ Ú©Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø²Ù†Ø¯Ù‡ Ø±Ø§ Ø§Ø² **Kafka** Ø¯Ø±ÛŒØ§ÙØª Ú©Ø±Ø¯Ù‡ØŒ Ø¨Ø§ **Spark Structured Streaming** ØªØ¬Ù…ÛŒØ¹ Ùˆ ØªØ­Ù„ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŒ Ø³Ù¾Ø³ Ù†ØªØ§ÛŒØ¬ Ø±Ø§ Ø¨Ù‡ **Prometheus Pushgateway** Ù…ÛŒâ€ŒÙØ±Ø³ØªØ¯ ØªØ§ Ø¯Ø± **Grafana** Ø¨Ù‡ Ø´Ú©Ù„ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ù¾ÙˆÛŒØ§ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´ÙˆÙ†Ø¯.

Kafka Ù†Ù‚Ø´ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø² Ø¯Ù†ÛŒØ§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø±Ø§ Ø¯Ø§Ø±Ø¯: ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ Ø¯Ø±Ø¨Ø§Ø±Ù‡Ù” Ù¾Ø±ÙˆØ§Ø²Ù‡Ø§ (`flight.events.v1`)ØŒ ÙˆØ¶Ø¹ÛŒØª Ø¢Ø¨â€ŒÙˆÙ‡ÙˆØ§ (`weather.events.v1`) Ùˆ Ø±Ø²Ø±Ùˆ Ù‡ØªÙ„â€ŒÙ‡Ø§ (`booking.events.v1`). Spark Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø² Ø§ÛŒÙ† Ø§Ø³ØªØ±ÛŒÙ…â€ŒÙ‡Ø§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†Ø¯ØŒ ØªÙ…ÛŒØ² Ùˆ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŒ Ø³Ù¾Ø³ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² **windowÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ (1min, 30d, 365d)** Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒÛŒ Ù…Ø§Ù†Ù†Ø¯:

- Ù†Ø±Ø® Ù„ØºÙˆ Ù¾Ø±ÙˆØ§Ø²ØŒ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ØªØ£Ø®ÛŒØ±ØŒ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù‚ÛŒÙ…Øª Ù‡ØªÙ„ (ADR)ØŒ Ùˆ Ù…ÛŒØ²Ø§Ù† Ù…Ø®Ø§Ø±Ø¬ Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ Ø±Ø§ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ **Ú†Ú©â€ŒÙ¾ÙˆÛŒÙ†ØªØŒ ÙˆØ§ØªØ±Ù…Ø§Ø±Ú© Ùˆ Trigger** Ú©Ù†ØªØ±Ù„ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ ØªØ§ Ù‡Ù… real-time Ø¨Ø§Ø´Ù†Ø¯ Ùˆ Ù‡Ù… Ù…Ù‚Ø§ÙˆÙ… Ø¯Ø± Ø¨Ø±Ø§Ø¨Ø± ØªØ£Ø®ÛŒØ± Ùˆ Ù‚Ø·Ø¹ÛŒ.

Ø¯Ø± Ù…Ø±Ø­Ù„Ù‡Ù” ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ØŒ ÛŒÚ© Ù…ØªØ±ÛŒÚ© Ø¬Ø¯ÛŒØ¯ Ø¨Ù‡ Ù†Ø§Ù… **`tourism_season_score`** Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯ â€” Ø´Ø§Ø®ØµÛŒ Û° ØªØ§ Û±Û°Û° Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø´Ù‡Ø± Ùˆ ÙØµÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ±Ú©ÛŒØ¨ Ú†Ù‡Ø§Ø± Ø¹Ø§Ù…Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯:

> Ù‚ÛŒÙ…ØªØŒ ÙˆØ¶Ø¹ÛŒØª Ù‡ÙˆØ§ØŒ Ù…ÛŒØ²Ø§Ù† Ø´Ù„ÙˆØºÛŒØŒ Ùˆ Ø§Ø¹ØªÙ…Ø§Ø¯Ù¾Ø°ÛŒØ±ÛŒ Ù¾Ø±ÙˆØ§Ø²Ù‡Ø§.

Ø§ÛŒÙ† Ø´Ø§Ø®Øµ Ø¨Ù‡â€ŒØµÙˆØ±Øª Ø²Ù†Ø¯Ù‡ Ø¯Ø± Prometheus Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ ØªØ§ Ø¯Ø± Grafana Ø¨ØªÙˆØ§Ù† Ø¨Ù‡ØªØ±ÛŒÙ† ÙØµÙ„ Ø³ÙØ± Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ **Ù‡Ø²ÛŒÙ†Ù‡ØŒ Ø´Ø±Ø§ÛŒØ· Ø¢Ø¨â€ŒÙˆÙ‡ÙˆØ§ Ùˆ ØªØ±Ø§Ú©Ù… Ú¯Ø±Ø¯Ø´Ú¯Ø±** Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ø±Ø¯.

------

### ğŸŒ Ø®Ø±ÙˆØ¬ÛŒ Ùˆ Ø§Ø±Ø²Ø´

Ø¯Ø± GrafanaØŒ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ Ø²Ù†Ø¯Ù‡ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù†Ø¯:

- Ù†Ù‚Ø´Ù‡Ù” Ø§ÛŒØªØ§Ù„ÛŒØ§ Ø¨Ø§ Ù†Ù‚Ø§Ø· Ø´Ù‡Ø±Ù‡Ø§ÛŒ Ù¾Ø±ØªØ±Ø¯Ø¯ (Geomap)
- Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ Ù…ÛŒÙ„Ù‡â€ŒØ§ÛŒ Ø§Ø² Ø¯Ù‡ ÙØ±ÙˆØ¯Ú¯Ø§Ù‡ Ù¾Ø±ØªØ±Ø§ÙÛŒÚ© (ÙˆØ±ÙˆØ¯ÛŒ/Ø®Ø±ÙˆØ¬ÛŒ)
- Ø¬Ø¯Ø§ÙˆÙ„ Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ Ø§Ø² Ù…Ø®Ø§Ø±Ø¬ Ø±ÙˆØ²Ø§Ù†Ù‡Ù” Ù‡ØªÙ„ Ø¯Ø± Ø´Ù‡Ø±Ù‡Ø§ÛŒ Ø¨Ø±ØªØ±
- Ùˆ ØªØ­Ù„ÛŒÙ„ ÙØµÙ„ÛŒ Ø§Ø² Ø¨Ù‡ØªØ±ÛŒÙ† Ø²Ù…Ø§Ù† Ø³ÙØ±

Ø¯Ø± Ù†ØªÛŒØ¬Ù‡ØŒ Ø§ÛŒÙ† Ø³ÛŒØ³ØªÙ… ÛŒÚ© **Ù¾Ù„ØªÙØ±Ù… Ù†Ø¸Ø§Ø±Øª Ùˆ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ø¨Ù„Ø§Ø¯Ø±Ù†Ú¯ Ø¨Ø±Ø§ÛŒ ØµÙ†Ø¹Øª Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ** Ø§ÛŒØ¬Ø§Ø¯ Ú©Ø±Ø¯Ù‡ Ø§Ø³Øª Ú©Ù‡ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ø±Ø§ÛŒ:

- Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ØªÙ‚Ø§Ø¶Ø§ÛŒ Ø³ÙØ±
- Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§
- Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ Ø¸Ø±ÙÛŒØª Ù¾Ø±ÙˆØ§Ø² Ùˆ Ø§Ù‚Ø§Ù…Øª
   Ø¨Ù‡ Ú©Ø§Ø± Ø±ÙˆØ¯.

------



### ğŸ§  **Prometheus Ú†ÛŒÙ‡ØŸ**

Prometheus ÛŒÙ‡ Ø§Ø¨Ø²Ø§Ø± **Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ùˆ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (metrics)** Ù‡Ø³Øª Ú©Ù‡ ØªÙˆØ³Ø· Ø´Ø±Ú©Øª SoundCloud Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯ Ùˆ Ø§Ù„Ø§Ù† ÛŒÚ©ÛŒ Ø§Ø² Ù¾Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ **DevOps Ùˆ Data Engineering** Ù…Ø­Ø³ÙˆØ¨ Ù…ÛŒØ´Ù‡.
 Ú©Ø§Ø±Ø´ Ø§ÛŒÙ†Ù‡ Ú©Ù‡:

- Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ (Ø§Ø¹Ø¯Ø§Ø¯ Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ Ù…Ø«Ù„ Ù†Ø±Ø®ØŒ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†ØŒ Ø¯Ù…Ø§ØŒ ØªØ£Ø®ÛŒØ± Ùˆ...) Ø±Ùˆ Ø§Ø² Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ Ø¬Ù…Ø¹ Ù…ÛŒâ€ŒÚ©Ù†Ù‡
- Ø§ÙˆÙ†â€ŒÙ‡Ø§ Ø±Ùˆ Ø¯Ø± ÛŒÙ‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù…Ø®ØµÙˆØµ Ø²Ù…Ø§Ù† (time-series DB) Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù‡
- Ø¨Ø¹Ø¯Ø´ Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒ Ø¨Ø§ Ø²Ø¨Ø§Ù† Ù¾Ø±Ø³â€ŒÙˆØ¬ÙˆÛŒ Ù…Ø®ØµÙˆØµ Ø®ÙˆØ¯Ø´ (PromQL) Ø§Ø²Ø´ Ø³Ø¤Ø§Ù„ Ø¨Ù¾Ø±Ø³ÛŒ
- Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø§ÛŒÙ† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø¹Ø¯Ø´ Ø¯Ø± **Grafana** Ø¨Ø±Ø§ÛŒ Ø¨ØµØ±ÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´Ù†

Ø§Ù…Ø§ ÛŒÚ© Ù†Ú©ØªÙ‡: Prometheus Ø¨Ù‡â€ŒØµÙˆØ±Øª Ø¹Ø§Ø¯ÛŒ **Ø®ÙˆØ¯Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ùˆ Ù…ÛŒâ€ŒÚ©Ø´Ù‡ (pull)**ØŒ ÛŒØ¹Ù†ÛŒ Ø®ÙˆØ¯Ø´ Ù…ÛŒâ€ŒØ±Ù‡ Ø³Ø±Ø§Øº Ø³Ø±ÙˆØ±Ù‡Ø§ Ùˆ Ø§Ø²Ø´ÙˆÙ† Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ Ø±Ùˆ Ù…ÛŒâ€ŒØ®ÙˆÙ†Ù‡.

------

### ğŸš€ **Pushgateway Ú†ÛŒÙ‡ØŸ**

Ú¯Ø§Ù‡ÛŒ Ù…Ø§ Ø³ÛŒØ³ØªÙ…ÛŒ Ø¯Ø§Ø±ÛŒÙ… (Ù…Ø«Ù„ Ú©Ø¯ ØªÙˆØŒ ÛŒØ¹Ù†ÛŒ Spark job) Ú©Ù‡ **Ø¨Ù‡â€ŒØµÙˆØ±Øª Ù…ÙˆÙ‚Øª ÛŒØ§ batch** Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ù‡ØŒ ÛŒØ¹Ù†ÛŒ Ø®ÙˆØ¯Ø´ Ù†Ù…ÛŒâ€ŒØªÙˆÙ†Ù‡ Ù‡Ù…ÛŒØ´Ù‡ Ù…Ù†ØªØ¸Ø± Ø¨Ù…ÙˆÙ†Ù‡ ØªØ§ Prometheus Ø¨ÛŒØ§Ø¯ Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡ Ø¨Ú¯ÛŒØ±Ù‡.
 Ø§ÛŒÙ†Ø¬Ø§ **Pushgateway** ÙˆØ§Ø±Ø¯ ØµØ­Ù†Ù‡ Ù…ÛŒØ´Ù‡ ğŸ‘‡

Pushgateway ÛŒÙ‡ Ø³Ø±ÙˆÛŒØ³ ÙˆØ§Ø³Ø·Ù‡ Ø§Ø³Øª Ø¨ÛŒÙ† Ú©Ø¯ Ù…Ø§ Ùˆ Prometheus:

- Ø¨Ø±Ù†Ø§Ù…Ù‡ (Ù…Ø«Ù„ Spark) Ø®ÙˆØ¯Ø´ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ Ø±Ùˆ **push (Ø§Ø±Ø³Ø§Ù„)** Ù…ÛŒâ€ŒÚ©Ù†Ù‡ Ø¨Ù‡ Pushgateway (Ù…Ø«Ù„Ø§Ù‹ Ø¨Ø§ `requests.post()` ØªÙˆÛŒ Ú©Ø¯Øª)
- Pushgateway Ø§ÙˆÙ† Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ Ø±Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù‡ Ùˆ Ø¯Ø± endpoint Ø®ÙˆØ¯Ø´ (`http://localhost:9091/metrics`) Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù…ÛŒâ€ŒØ°Ø§Ø±Ù‡
- Ø¨Ø¹Ø¯ Prometheus Ø·Ø¨Ù‚ ØªÙ†Ø¸ÛŒÙ…Ø§ØªØ´ (Ø¯Ø± ÙØ§ÛŒÙ„ `prometheus.yml`) Ù…ÛŒØ§Ø¯ Ùˆ Ø§ÙˆÙ† Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ Ø±Ùˆ Ø§Ø² Pushgateway **pull** Ù…ÛŒâ€ŒÚ©Ù†Ù‡



**ÙˆØ§ØªØ±Ù…Ø§Ø±Ú© (Watermark)**

- ÛŒØ¹Ù†ÛŒ Â«ØªØ§ Ú†Ù‡ Ø­Ø¯ ØªØ£Ø®ÛŒØ± Ø±Ùˆ Ù‚Ø¨ÙˆÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ù…Â». ØªÙˆ Ú©Ø¯Øª: `withWatermark("ingest_time", "45 seconds")` â†’ Ø±ÙˆÛŒØ¯Ø§Ø¯Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø®ÛŒÙ„ÛŒ Ø¯ÛŒØ± Ù…ÛŒâ€ŒØ±Ø³Ù† (Ø¨ÛŒØ´ Ø§Ø² 45s) Ø¯ÛŒÚ¯Ù‡ ÙˆØ§Ø±Ø¯ Ù…Ø­Ø§Ø³Ø¨Ù‡Ù” Ù¾Ù†Ø¬Ø±Ù‡ Ù†Ù…ÛŒâ€ŒØ´Ù†.

**Ù¾Ù†Ø¬Ø±Ù‡Ù” Ø²Ù…Ø§Ù†ÛŒ (Windowing)**

- Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø±ÙˆÛŒØ¯Ø§Ø¯Ù‡Ø§ÛŒ Ø§Ø³ØªØ±ÛŒÙ… Ø¨Ø± Ø§Ø³Ø§Ø³ Ø²Ù…Ø§Ù†Ø› Ù…Ø«Ù„ Â«Ù‡Ø± Û± Ø¯Ù‚ÛŒÙ‚Ù‡Â». ØªÙˆ Ú©Ø¯Øª: `window(col("ingest_time"), "1 minute")` Ùˆ Ù‡Ù…â€ŒÚ†Ù†ÛŒÙ† Ù¾Ù†Ø¬Ø±Ù‡â€ŒÙ‡Ø§ÛŒ Rolling Ù…Ø«Ù„ `30 days` Ùˆ `365 days`.

**ØªØ¬Ù…ÛŒØ¹â€ŒÙ‡Ø§ (Aggregations)**

- Ù…Ø­Ø§Ø³Ø¨Ù‡Ù” Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ø±ÙˆÛŒ Ù¾Ù†Ø¬Ø±Ù‡: `count`, `avg`, `sum` Ùˆâ€¦ (Ù…Ø«Ù„Ø§Ù‹ ØªØ¹Ø¯Ø§Ø¯ Ø±Ø²Ø±Ùˆ Ø¯Ø± Ø¯Ù‚ÛŒÙ‚Ù‡ØŒ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ØªØ£Ø®ÛŒØ±ØŒ Ù†Ø±Ø® Ù„ØºÙˆ).

**Ú©Ù†ØªØ±Ù„ Ú©Ø§Ø±Ø¯ÛŒÙ†Ø§Ù„ÛŒØªÛŒ (Cardinality Control)**

- ÛŒØ¹Ù†ÛŒ Ú©Ù… Ù†Ú¯Ù‡â€ŒØ¯Ø§Ø´ØªÙ† ØªØ¹Ø¯Ø§Ø¯ Ø³Ø±ÛŒâ€ŒÙ…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ ØªØ§ Prometheus Ù…Ù†ÙØ¬Ø± Ù†Ø´Ù‡. ØªÙˆ Ú©Ø¯Øª Ø¨Ø§ **Top-N** (Ù…Ø«Ù„Ø§Ù‹ 10 Ø´Ù‡Ø±/ÙØ±ÙˆØ¯Ú¯Ø§Ù‡ Ø¨Ø±ØªØ±) Ù…ÛŒâ€ŒÙØ±Ø³ØªÛŒØ› Ø¨Ù‚ÛŒÙ‡ Ø±Ùˆ Ù¾ÙˆØ´ Ù†Ù…ÛŒâ€ŒÚ©Ù†ÛŒ.

**Ú†Ú©â€ŒÙ¾ÙˆÛŒÙ†Øª (Checkpoint)**

- Ø°Ø®ÛŒØ±Ù‡Ù” ÙˆØ¶Ø¹ÛŒØª Ø§Ø³ØªØ±ÛŒÙ… Ø¨Ø±Ø§ÛŒ Ø§Ø²Ø³Ø±Ú¯ÛŒØ±ÛŒ Ø§Ù…Ù†. ØªÙˆ Ú©Ø¯Øª: `option("checkpointLocation", "/tmp/chk_*")`. Ø§Ú¯Ø± Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø² Ù†Ùˆ Ø¨Ø§Ù„Ø§ Ø¨ÛŒØ§Ø¯ØŒ Ø§Ø² Ù‡Ù…ÙˆÙ†â€ŒØ¬Ø§ Ø§Ø¯Ø§Ù…Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡.

**ØªØ±ÛŒÚ¯Ø± (Trigger)**

- ØªØ¹ÛŒÛŒÙ† Ø¯ÙˆØ±Ù‡Ù” Ø§Ø¬Ø±Ø§ÛŒ Ù…ÛŒÚ©Ø±ÙˆØ¨Ú†â€ŒÙ‡Ø§; ØªÙˆ Ú©Ø¯Øª: `trigger(processingTime="10 seconds")` â†’ Ù‡Ø± 10 Ø«Ø§Ù†ÛŒÙ‡ Ø®Ø±ÙˆØ¬ÛŒ Ùˆ Push.

**Ø³Ù„Ø§Ù…Øª Ø§Ø³ØªØ±ÛŒÙ… (Stream Health)**

- Ø¨Ø§ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ú©Ù…Ú©ÛŒ Ù…ÛŒâ€ŒÙÙ‡Ù…ÛŒ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ±Ø³Ù‡ ÛŒØ§ Ù†Ù‡ (Ù…Ø«Ù„ `tourism_ingest_records_per_trigger`) Ùˆ Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ `foreachBatch count=`Ø› Ù‡Ù…Ú†Ù†ÛŒÙ† Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ØªØ£Ø®ÛŒØ±/Ù†Ø±Ø® Ù„ØºÙˆ Ù‡Ù… Ù†Ø´Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ù„Ø§Ù…Øªâ€ŒØ§Ù†Ø¯.

------

### Ø±ÙˆØ´â€ŒÙ‡Ø§/Ù…ØªØ¯Ù‡Ø§ÛŒ Ù…Ù‡Ù…ÛŒ Ú©Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯ÛŒ

- **Timestamp Ø³Ø®Øªâ€ŒØ¬Ø§Ù†**: Ø§Ú¯Ø± `event_ts/ingest_ts` Ø®Ø§Ù„ÛŒ Ø¨ÙˆØ¯ØŒ Ø§Ø² `kafka_ts` Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯ÛŒ (Ø¨Ø§ `when/otherwise`).
- **Watermark + Tumbling/Rolling windows**: Û± Ø¯Ù‚ÛŒÙ‚Ù‡ØŒ Û³Û° Ø±ÙˆØ²ØŒ Û³Û¶Ûµ Ø±ÙˆØ².
- **foreachBatch**: Ø®Ø±ÙˆØ¬ÛŒ Ù‡Ø± Ù¾Ù†Ø¬Ø±Ù‡ Ø±Ø§ Ø¨Ù‡ **Pushgateway** Ù…ÛŒâ€ŒÙØ±Ø³ØªÛŒ (`push_metrics`).
- **Top-N Ø§Ù†ØªØ®Ø§Ø¨ÛŒ**: Ø¨Ø±Ø§ÛŒ Ø´Ù‡Ø±Ù‡Ø§/ÙØ±ÙˆØ¯Ú¯Ø§Ù‡â€ŒÙ‡Ø§ (Ú©Ø§Ù‡Ø´ Ú©Ø§Ø±Ø¯ÛŒÙ†Ø§Ù„ÛŒØªÛŒ).
- **Enrichment Ø±Ø²Ø±Ùˆ**: Ø³Ø§Ø®Øª `spend_eur = adr_proxy * rooms * nights` Ùˆ `arrival_day`.
- **Ø§Ù…Ø±ÙˆØ²**: ØªØ¬Ù…ÛŒØ¹ Ø±ÙˆØ²Ø§Ù†Ù‡Ù” ÙˆØ±ÙˆØ¯ÛŒ/Ù‡Ø²ÛŒÙ†Ù‡Ù” Ù‡ØªÙ„ Ø¨Ø±Ø§ÛŒ Top Ø´Ù‡Ø±Ù‡Ø§.
- **ÙØ±ÙˆØ¯Ú¯Ø§Ù‡â€ŒÙ‡Ø§**: ÙˆØ±ÙˆØ¯ÛŒ/Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø± Ø­Ø³Ø¨ `origin_iata`/`destination_iata` + Ù…Ø¬Ù…ÙˆØ¹ Ú©Ù„ Ù¾Ø±ÙˆØ§Ø²Ù‡Ø§.
- **Geomap**: Ù†Ú¯Ø§Ø´Øª `city_id/city_name` Ø¨Ù‡ `lat/lon` Ø¨Ø§ **UDF** Ùˆ Ù¾ÙˆØ´ Ù…ØªØ±ÛŒÚ© `tourism_city_bookings_geo`.
- **Rolling ØªØ­Ù„ÛŒÙ„ÛŒ**: Ù…Ø§Ù‡/ÙØµÙ„ (bookings/spend) Ø¯Ø± Û³Û¶Ûµ Ø±ÙˆØ².
- **Season Score**: Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø±ØµØ¯Ú©ÛŒ (`percentile_approx`) + Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª/Ù‡ÙˆØ§/Ø´Ù„ÙˆØºÛŒ/Ø§Ø¹ØªÙ…Ø§Ø¯Ù¾Ø°ÛŒØ±ÛŒ â†’ Ø§Ù…ØªÛŒØ§Ø² Û°..Û±Û°Û°.
- **Ø­ÙØ§Ø¸Øª Ø§Ø² Ù†Ø§Ù„â€ŒÙ‡Ø§**: `coalesce`ØŒ Ùˆ Ù†Ú¯Ù‡Ø¨Ø§Ù† ØªÙ‚Ø³ÛŒÙ… Ø¨Ø± ØµÙØ± Ø¯Ø± Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ (minâ€“max).
- **Join Ú†Ù†Ø¯Ù…Ù†Ø¨Ø¹Ù‡**: ØªØ±Ú©ÛŒØ¨ Ø¢Ù…Ø§Ø± ÙØµÙ„-Ø´Ù‡Ø±ÛŒ Ø§Ø² Ù¾Ø±ÙˆØ§Ø²/Ù‡ÙˆØ§/Ø±Ø²Ø±Ùˆ Ø¨Ø±Ø§ÛŒ Ø§Ù…ØªÛŒØ§Ø² ÙØµÙ„.





# Ø³Ø®Ù‡ ØªÙ…ÛŒØ²Ù Ú©ÙˆØ¦Ø±ÛŒâ€ŒÙ‡Ø§ + ØªÙ†Ø¸ÛŒÙ… Legend Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù†Ù…ÙˆØ¯Ø§Ø±

## 1) ÙˆØ±ÙˆØ¯ÛŒ ÙØ±ÙˆØ¯Ú¯Ø§Ù‡â€ŒÙ‡Ø§ (Û± Ø¯Ù‚ÛŒÙ‚Ù‡ Ø§Ø®ÛŒØ±) â€” Bar (horizontal)

- **PromQL**

  ```
  topk(10,
    sum without (instance, job) (tourism_airport_flights_per_min{direction="inbound"})
  )
  
  ```

Legend: {{airport}}

Ù†Ú©ØªÙ‡: Ø§Ú¯Ø± Ú†Ù†Ø¯ Ø¢Ø¨Ø¬Ú©Øª Ø§Ø² ÛŒÙ‡ ÙØ±ÙˆØ¯Ú¯Ø§Ù‡ Ø§Ø² Ù†ÙˆØ¯Ù‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¨ÛŒØ§Ø¯ØŒ Ø§ÛŒÙ† sum Ø§ÙˆÙ†â€ŒÙ‡Ø§ Ø±Ùˆ ÛŒÚ©ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ù‡ ØªØ§ Legend ØªÚ©Ø±Ø§Ø±ÛŒ Ù†Ø´Ù‡.

## 2) Ø®Ø±ÙˆØ¬ÛŒ ÙØ±ÙˆØ¯Ú¯Ø§Ù‡â€ŒÙ‡Ø§ (Û± Ø¯Ù‚ÛŒÙ‚Ù‡ Ø§Ø®ÛŒØ±) â€” Bar (horizontal)

- **PromQL**

  ```
  topk(10,
    sum without (instance, job) (tourism_airport_flights_per_min{direction="outbound"})
  )
  
  ```

**Legend**: `{{airport}}`

## Û³) Ú©Ù„ Ù¾Ø±ÙˆØ§Ø²Ù‡Ø§ Ø¯Ø± Ø¯Ù‚ÛŒÙ‚Ù‡ â€” Stat

- **PromQL**

  ```
  sum without (instance, job) (tourism_flights_total_per_min)
  
  ```

**Legend**: (Ù†ÛŒØ§Ø² Ù†ÛŒØ³Øª â€” ÛŒÚ© Ø¹Ø¯Ø¯ Ø¨Ø²Ø±Ú¯ Ù†Ù…Ø§ÛŒØ´ Ø¨Ø¯Ù‡)

**Reduce**: Last (not null)

## 4) Ù„ÛŒØ¯Ø±Ø¨ÙØ±Ø¯ Â«Ù‡Ù…ÛŒÙ† Ø­Ø§Ù„Ø§Â» (Booking/minutely) â€” Bar

- **PromQL**

  ```
  topk(10,
    sum without (instance, job, period) (tourism_city_bookings_top{period="1m"})
  )
  
  ```

**Legend**: `{{city_name}}`

**Axes**: Ø¨Ø±Ú†Ø³Ø¨ Ù…Ø­ÙˆØ± X = Â«Ø´Ù‡Ø±Â»ØŒ Y = Â«Ø±Ø²Ø±Ùˆ Ø¯Ø± Ø¯Ù‚ÛŒÙ‚Ù‡Â»

## 5) Ù„ÛŒØ¯Ø±Ø¨ÙØ±Ø¯ Û³Û° Ø±ÙˆØ² Ø§Ø®ÛŒØ± â€” Bar

- **PromQL**

  ```
  topk(10,
    sum without (instance, job, period) (tourism_city_bookings_top{period="30d"})
  )
  
  ```

**Legend**: `{{city_name}}`

## 6) Ù„ÛŒØ¯Ø±Ø¨ÙØ±Ø¯ Û³Û¶Ûµ Ø±ÙˆØ² Ø§Ø®ÛŒØ± â€” Bar

- **PromQL**

  ```
  topk(10,
    sum without (instance, job, period) (tourism_city_bookings_top{period="365d"})
  )
  
  ```

**Legend**: `{{city_name}}`



------

# 9) Ù†Ù‚Ø´Ù‡ Ø¯Ø§Øº Ø±Ø²Ø±ÙˆÙ‡Ø§ÛŒ Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ â€” Geomap

**Ù‡Ø¯Ù:** Â«Ù†Ù‚Ø§Ø· Ø¯Ø§ØºÂ» Ø±Ø²Ø±Ùˆ Ø±ÙˆÛŒ Ù†Ù‚Ø´Ù‡ (Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ).

**Query (ÛŒÚ© Ø³Ø±ÛŒ Ø¨Ù‡ Ø§Ø²Ø§ÛŒ Ù‡Ø± Ø´Ù‡Ø± Ø¨Ø§ Ù…Ø®ØªØµØ§Øª):**

```
sum by (city_id, city_name, lat, lon) (
  tourism_city_bookings_geo
)

```

**ØªÙ†Ø¸ÛŒÙ…Ø§Øª Geomap:**

- **Query options â†’ Format = Table** Ø³Ù¾Ø³ **Labels to fields** Ø±Ùˆ Ø±ÙˆØ´Ù† Ú©Ù†.
- **Latitude field:** `lat`
- **Longitude field:** `lon`
- **Name/Tooltip:** `{{city_name}}`
- **Size/Color:** Ù…Ù‚Ø¯Ø§Ø± Ù…ØªØ±ÛŒÚ© (Ø®Ø±ÙˆØ¬ÛŒ Ú©ÙˆØ¦Ø±ÛŒ)
- (Optional) **Value â†’ Last not null**

> Ø§Ú¯Ø± Ù†Ù‚Ø·Ù‡â€ŒÙ‡Ø§ Ø¸Ø§Ù‡Ø± Ù†Ù…ÛŒâ€ŒØ´Ù†ØŒ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø¨Ù‡ Ø®Ø§Ø·Ø± Ø§ÛŒÙ†Ù‡ Ú©Ù‡ Format Ù‡Ù†ÙˆØ² Â«Time seriesÂ» Ù…ÙˆÙ†Ø¯Ù‡ ÛŒØ§ mapping `lat/lon` Ø±ÙˆÛŒ labels Ø³Øª Ù†Ø´Ø¯Ù‡.

# 12) Ø±Ø²Ø±Ùˆ Rolling Ù…Ø§Ù‡Ø§Ù†Ù‡ (Û±Û² Ù…Ø§Ù‡) â€” Bar (categorical)

**Ù‡Ø¯Ù:** Ø±ÛŒØªÙ… ÙØµÙ„ÛŒ Ø±Ø²Ø±ÙˆÙ‡Ø§ (Rolling 365d)Ø› Ù…Ø­ÙˆØ± X = Ù…Ø§Ù‡.

**A) Ù†Ù‚Ø·Ù‡Ù” ÙØ¹Ù„ÛŒÙ Ù‡Ø± Ù…Ø§Ù‡**

```
sum by (month) (
  tourism_month_bookings_rolling
)

```

**Legend:** `Ù…Ø§Ù‡ {{month}}`
 **Axis:** X Ø±Ø§ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ (Category) Ø¨Ú¯Ø°Ø§Ø±Ø› Ø¨Ø±Ø§ÛŒ ØªØ±ØªÛŒØ¨ Ø¯Ø±Ø³ØªØŒ Sort by label `month` ÛŒØ§ Ø§Ø² Override â†’ Value mappings Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†.



------

# 13) Ù‡Ø²ÛŒÙ†Ù‡ Rolling Ù…Ø§Ù‡Ø§Ù†Ù‡ (EUR) â€” Bar



```
sum by (month) (
  tourism_month_spend_rolling_eur
)

```

**Legend:** `Ù…Ø§Ù‡ {{month}}`

# 14) Ø±Ø²Ø±Ùˆ Rolling ÙØµÙ„ÛŒ â€” Pie ÛŒØ§ Bar



```
sum by (season) (
  tourism_season_bookings_rolling
)

```

**Legend:** `{{season}}`



# 15) Ù‡Ø²ÛŒÙ†Ù‡ Rolling ÙØµÙ„ÛŒ (EUR) â€” Pie ÛŒØ§ Bar



```
sum by (season) (
  tourism_season_spend_rolling_eur
)

```

**Legend:** `{{season}}`